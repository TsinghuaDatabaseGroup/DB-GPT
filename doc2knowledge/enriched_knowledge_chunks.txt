[{"name": "unused_and_redundant_index", "content": "This function checks for the presence of unused or redundant indexes in a table that is related to a query. Unused indexes are those that have not been used for a long time, while redundant indexes are those that are not needed for the query. If the table is not large or there are no unused or redundant indexes, or if the query involves a select operation, then the function is not a root cause. Otherwise, the function identifies the unused and redundant indexes and provides suggestions to clean them up. The threshold for identifying unused indexes is not specified in the code."}, {"name": "too_many_index", "content": "This function checks for the presence of too many indexes in a table, which can negatively impact the performance of insert and update operations. If the table structure is not available or the select type is not appropriate, this is not a root cause. If there are a large number of indexes in the table, the function identifies the related tables and provides details on the number of indexes. In this case, the function is a root cause and suggests that too many indexes can slow down insert, delete, and update statements. The threshold for the number of indexes is determined by the variable \"index_number_threshold\"."}, {"name": "missing_index", "content": "This function checks for the presence of a required index using a workload-index-recommend interface. If the recommended index information is available, it indicates that a required index is missing and provides a suggestion for the recommended index. If the information is not available, it is not a root cause for the issue."}, {"name": "index_not_used", "content": "If the query plan does not utilize an index, it may indicate a performance issue"}, {"name": "index_not_used", "content": "If the index plan is not used, it may be due to invalid statistics, index invalidation, implicit type conversion, or pattern matching filter conditions."}, {"name": "index_not_used", "content": "If the index plan is not used, it may be caused by invalid statistics, index invalidation, implicit type conversion, or pattern matching filter conditions."}, {"name": "database_bottleneck", "content": "To determine if the bottleneck is on the database side, check the CPU usage of the host where the database is located, relevant views in the database, or related metrics on OPS. If there are very few active sessions in the database, it is highly likely that the database throughput cannot increase."}, {"name": "business_bottleneck", "content": "If the database side does not perceive obvious business pressure, or the pressure is not large enough and resource consumption is very low (e.g., CPU usage is less than IO%, the number of active sessions is single-digit), it is recommended to investigate on the business side. Common causes may include: application server resource exhaustion (insufficient CPU/IO/memory), high network latency between application server and database, slow processing of query results on the application server, resulting in slow transmission of SQL statements within transactions to the database, etc."}, {"name": "bottleneck_database_throttling", "content": "This event indicates that the database has flow control enabled to ensure RTO (Recovery Time Objective). It is recommended to consider disabling flow control during performance testing if it significantly affects performance."}, {"name": "concurrency_workload_workload_contention", "content": "This code is designed to diagnose workload contention issues in a database system. The function checks for several potential causes of contention, including abnormal CPU and memory resource usage, insufficient space in the database data directory, and excessive connections or thread pool usage. If any of these issues are detected, the function provides a detailed report of the problem and suggests potential solutions. If no issues are found, the function returns \"not a root cause\"."}, {"name": "concurrency_workload_database_wait_event", "content": "This function checks if there is a wait event in the database. If there is a wait event, it retrieves the wait status and wait event information and stores it in the detail dictionary. If the detail dictionary already has wait event information, it suggests that there is no root cause for the issue. Otherwise, it suggests that the wait event may be a root cause for the issue. If there is no wait event information, it suggests that there is no root cause for the issue. Therefore, the presence of wait event information is a root cause for the issue, while the absence of wait event information is not a root cause."}, {"name": "concurrency_workload_CPU_analysis_and_diagnostics", "content": "The code provided is analyzing the CPU workload and providing diagnostics based on certain conditions. \n\nFirst, the code retrieves CPU information using the \"getcpu\" function. It initializes variables \"sql_cpu\", \"flag_cpu\", and \"cpuinfo\". \n\nThen, it enters a loop to process each CPU resource. It concatenates SQL queries using the values from each resource, which will be used for further analysis. \n\nThe code then checks the value of the \"r\" attribute in each resource. If it is less than or equal to the variable \"cpun\" (representing the number of CPU threads), it indicates that the CPU load is not high. However, if it is greater than \"cpun\" but less than or equal to \"cpun\" multiplied by 2, it suggests that the CPU load is relatively high. If the value of \"r\" exceeds \"cpun\" multiplied by 2, it indicates a high CPU load with potential risks. The variable \"flag_cpu\" is incremented accordingly to keep track of the CPU load status.\n\nThe code then examines the value of the \"us\" attribute (representing CPU usage). If it is less than 20, it suggests that the CPU usage is not high. If it is between 20 and 80 (inclusive), it indicates normal CPU usage. If it is between 80 and 95 (inclusive), it suggests relatively high CPU usage. If the value exceeds 95 and the \"r\" value is greater than \"cpun\" multiplied by 2, it indicates a high CPU usage with a potential bottleneck. Otherwise, it concludes that the CPU is currently not experiencing performance bottlenecks.\n\nNext, the code evaluates the value of the \"sys\" attribute (representing system CPU usage). If it is less than 15, it suggests normal system CPU usage. If it is between 15 and 30 (inclusive), it indicates relatively high usage and requires attention to potential system issues. If it exceeds 30, it suggests significantly high system CPU usage, indicating the presence of serious vulnerabilities.\n\nBy analyzing the CPU information and applying various conditions, the code provides diagnostic information in the variable \"cpuinfo\". The variable \"flag_cpu\" keeps track of the number of identified CPU load issues."}, {"name": "concurrency_workload_Memory_usage_analysis_diagnosis", "content": "The code lines are analyzing and diagnosing the memory usage of a system. The code first retrieves the memory information using the \"getmem\" function. Then, it fetches the long-term memory information using the \"getltmem\" function with specific parameters. \n\nNext, the code initializes variables to store information about memory and swap usage. There are also flag variables that indicate whether there are any memory or swap issues.\n\nThe code then constructs a SQL query to retrieve specific memory information for each record obtained from the \"getmem\" function. Based on the retrieved information, the code analyzes the memory usage and assigns appropriate diagnostic messages to the \"mem_info\" variable. \n\nIf the physical memory usage exceeds 90% and the free memory is below 200M and above 100M, it indicates that the physical memory usage is high and the available memory is low, which may pose performance risks. Similarly, if the physical memory usage exceeds 90% and the free memory is below 100M, it suggests a high memory usage and a significant performance risk.\n\nIf the physical memory usage exceeds 20% of the recent average, it is recommended to perform further checks. \n\nThe code also checks the swap usage. If the swap usage is above 50% and below 80%, it indicates a high swap usage and suggests further investigation. If the swap usage exceeds 80%, it suggests a high swap usage and recommends immediate investigation.\n\nAfter analyzing each record, the code appends the diagnostic messages for memory and swap usage to the respective variables.\n\nFinally, the code removes the last \"union all\" from the constructed SQL query.\n\nIn conclusion, the code analyzes the memory and swap usage of a system and generates diagnostic messages based on the specific threshold values and recent average usage. These messages provide insights into any potential memory and swap issues that may affect the system's performance."}, {"name": "concurrency_workload_file_system_diagnostic_analysis", "content": "The code provided is diagnosing the usage and availability of file systems. \n\nThe variable `fs` stores the file systems retrieved using the `getfs()` function. \n`fs_info` is an empty string that will be used to store diagnostic information about the file systems. \n`flag_fs` is an integer variable initialized to 0 and will be used to count the number of file systems with issues. \n\nThe code then enters a loop where it iterates over each file system in `fs`. Within the loop, the code appends SQL queries to the `sql_fs` string. These queries collect information about the file system, such as its name (`fsmp`) and percentage of disk space used (`fspct`).\n\nThe code then proceeds to analyze each file system individually. If the file system's disk usage is between 80% and 95% and the amount of free space (`fsres`) is less than 500MB, a diagnostic message is added to `fs_info` indicating that the file system's usage is high and its free space is low. The `flag_fs` variable is incremented to indicate that an issue has been detected.\n\nSimilarly, if the file system's usage is between 80% and 95% and the free space is greater than 5GB, another diagnostic message is added to `fs_info` indicating that the file system's usage is high but its free space is sufficient. `flag_fs` is incremented again in this case.\n\nIf the file system's usage is equal to or greater than 95%, a diagnostic message is added to `fs_info` indicating that the file system's usage exceeds the critical threshold.\n\nFinally, if none of the above conditions are true, which means the file system's usage is below 80%, a diagnostic message is added to `fs_info` stating that the file system's usage is normal.\n\nIn summary, this code diagnoses the usage and availability of file systems and provides relevant diagnostic information based on pre-defined thresholds. The `sql_fs` and `fs_info` variables store information for further analysis and reporting. The `flag_fs` variable keeps track of the number of file systems with issues identified."}, {"name": "concurrency_workload_disk_group_usage_diagnostic_analysis", "content": "The provided code appears to be a diagnostic script related to monitoring the usage of disk groups. The code iterates over a list called 'dg' and dynamically constructs a SQL query called 'sql_dg' by concatenating strings. The constructed query combines the names and percentages of disk groups ('dgname' and 'dgpct') using the \"union all\" clause.\n\nAfter constructing the SQL query, the code includes a series of conditional statements to analyze the disk group usage. If the percentage ('dgpct') is greater than 80 and less than 95, and the free space ('dgfree') is less than 2048, a diagnostic message is appended to the 'dg_info' string indicating that the disk group usage is high and the available space is low. The 'flag_dg' variable is incremented to indicate that a disk group exceeding the threshold has been identified.\n\nSimilarly, if the percentage is greater than 80 and less than 95, but the free space is greater than 10240, another diagnostic message is appended, indicating that the disk group usage is relatively high but the available space is sufficient. Again, 'flag_dg' is incremented.\n\nIf the percentage is equal to or greater than 95, a diagnostic message is appended to 'dg_info' indicating that the disk group usage is significantly exceeding the warning limit. 'flag_dg' is incremented accordingly.\n\nIf none of the above conditions are met, a message indicating normal disk group usage is appended to 'dg_info'.\n\nThe final line of the code trims off the trailing \"union all\" from the constructed SQL query.\n\nIn summary, this code analyzes the usage of disk groups and provides diagnostic messages based on defined thresholds and conditions. It iterates over a list of disk group information, constructs a SQL query, and appends diagnostic messages based on the calculated values."}, {"name": "concurrency_workload_session_diagnostic_analysis", "content": "The function retrieves session information from the database. It starts by initializing the variables for session percentage (sesspct), session information (sess_info), and a flag for session (flag_sess). \n\nNext, it iterates through each element in sesspct and constructs a SQL query based on the values retrieved. It also checks if the session percentage is above 90%. If it is, a diagnostic message is added to sess_info indicating that the session percentage is too high and requires attention. Additionally, the flag_sess variable is incremented. If the session percentage is below or equal to 90%, a different diagnostic message is added to sess_info indicating that the session percentage is normal.\n\nThe constructed SQL query is then truncated to remove the trailing \"union all\" statement.\n\nOverall, this code performs a diagnostic analysis on session information, checking for high session percentages and providing relevant diagnostic messages."}, {"name": "concurrency_workload_high_cpu_usage", "content": "High CPU usage can cause slow SL execution and impact overall system performance"}, {"name": "concurrency_workload_high_cpu_usage_flame_graph", "content": "Flame graph analysis can be used to identify functions with high CPU usage and potential performance issues"}, {"name": "concurrency_workload_slow_overall_performance", "content": "The overall performance of the system is slow, causing high latency for business interfaces or not meeting customer expectations"}, {"name": "concurrency_workload_high_cpu_usage", "content": "High CPU usage can cause performance issues in the database system"}, {"name": "concurrency_workload_high_IO", "content": "If the IO utilization is high or there are abnormal IO metrics such as high r await or high Vawalt, it may indicate IO issues. Possible causes include cache/RAID configuration problems or disk throttling. To analyze the IO consumption of threads, you can use tools like pidstat or iotop. If the IO consumption is mainly caused by TPLworker threads, it means that user SQL queries are consuming a lot of IO. You can use the lwtid from pg_thread_wait_status to find the corresponding tid and sessionid, and then use the tid/sessionid to find the session information and specific queries from pg_stat_activity. To optimize the queries and reduce IO consumption, refer to the performance tuning chapter."}, {"name": "concurrency_workload_abnormal_IO", "content": "If the IO utilization is high or there are abnormal IO metrics such as high r await or high Vawalt, it may indicate IO issues. Possible causes include cache/RAID configuration problems or disk throttling. To analyze the IO consumption of threads, you can use tools like pidstat or iotop. If the IO consumption is mainly caused by TPLworker threads, it means that user SQL queries are consuming a lot of IO. You can use the lwtid from pg_thread_wait_status to find the corresponding tid and sessionid, and then use the tid/sessionid to find the session information and specific queries from pg_stat_activity. To optimize the queries and reduce IO consumption, refer to the performance tuning chapter."}, {"name": "concurrency_workload_memory_full", "content": "If the memory is full, it can cause slow program execution. To diagnose this issue, we need to identify the process with abnormal memory usage. In this case, we only consider the abnormal memory usage of the database process. For other processes, they are not representative and will not be described in detail here. To analyze the high memory usage of the database process, please refer to the relevant chapter on overall performance analysis."}, {"name": "concurrency_workload_abnormal_persistent_events", "content": "Abnormal persistent events in the database can impact overall performance. These events can be categorized as STATS, UNUCX EVENT, LOXXEVENT, and IO BVENT."}, {"name": "concurrency_workload_long_term_performance_degradation", "content": "Long-term performance degradation refers to a scenario where performance fluctuates over a certain period of time (e.g., hours). This can be identified by comparing performance reports from different time periods and analyzing differences in metrics such as top SQL, top wait events, load profile, cache/IO stats, and object stats."}, {"name": "concurrency_workload_short_term_performance_fluctuation", "content": "Short-term performance fluctuation refers to performance fluctuations that occur within a short period of time (e.g., seconds). These fluctuations may not be captured by default performance views, as they often show cumulative values. Refer to the chapter on analyzing performance fluctuations in the overall performance slow analysis for more information on how to diagnose and address short-term performance fluctuations."}, {"name": "concurrency_workload_high_cpu", "content": "If the CPU usage is high, it can cause overall performance slowdown"}, {"name": "concurrency_workload_high_io", "content": "If the IO usage is high, it can cause overall performance slowdown"}, {"name": "concurrency_workload_high_memory", "content": "If the memory usage is high, it can cause overall performance slowdown"}, {"name": "concurrency_workload_abnormal_events", "content": "If there are abnormal events, such as concurrent updates, it can cause overall performance slowdown"}, {"name": "concurrency_workload_performance_jitter", "content": "If there is performance jitter, it can cause overall performance slowdown"}, {"name": "concurrency_workload_high_cpu", "content": "High CPU usage in the database can be caused by poorly optimized SQL queries."}, {"name": "concurrency_workload_high_io", "content": "High IO can be caused by user statements that result in excessive physical reads. It can be identified by checking the 'n blocks fetched' and 'n blocks hit' fields in the dbe_pert_statement/dhe_pert_summary_statement views. If the difference between these two fields is high, it indicates a high number of physical reads. Additionally, the 'wait status' and 'wait event' fields in the pg_thread_wait_status view can be checked to see if there are any IO-related events or data file reads. The dhe_perf_local_active_session/gs_asp views can also be queried to check for records with Query events related to 'IO EVENT/DataFileRead' during a specific time period. Slow SQL queries with a high difference in 'n blocks fetched' and 'n blocks hit' fields or high data IO time can also indicate high IO. In the case of slow SQL, the 'details' field may contain information about the events causing the high IO."}, {"name": "concurrency_workload_high_memory_usage", "content": "High memory usage in the database can lead to performance issues. It is important to analyze and identify the specific areas of memory consumption."}, {"name": "concurrency_workload_slow_queries", "content": "Slow queries can cause overall performance degradation. It is important to identify the specific wait events and analyze their impact on performance."}, {"name": "concurrency_workload_performance_jitter", "content": "Performance jitter refers to fluctuations in performance over a period of time. It can be analyzed at different time scales."}, {"name": "concurrency_workload_performance_slow", "content": "The overall performance is slow, which does not meet the latency requirements of customer jobs or customer expectations."}, {"name": "concurrency_workload_performance_slow_wait_events", "content": "The overall performance is slow, and the wait events need to be analyzed to identify potential bottlenecks."}, {"name": "concurrency_workload_concurrent_query_optimization", "content": "GaussDB supports optimizing complex query execution using operator concurrency when system CU, memory, and IO resources are sufficient."}, {"name": "concurrency_workload_high_memory_usage", "content": "If the database process memory usage is consistently high, it can indicate memory overload."}, {"name": "concurrency_workload_high_concurrency_memory_usage", "content": "If the number of connections to the server is too high, it can lead to high memory usage."}, {"name": "concurrency_workload_high_memory_usage_sql", "content": "Some SQL statements may have high memory usage, leading to temporary memory spikes."}, {"name": "concurrency_workload_high_memory_usage", "content": "If the database process memory usage is consistently high, it can indicate memory overload."}, {"name": "concurrency_workload_memory_overload", "content": "If the memory usage of the database process is high, it can be caused by memory accumulation or other reasons"}, {"name": "concurrency_workload_memory_overload", "content": "In some cases, memory overload can cause cluster restarts, making it difficult to locate the cause of memory overload in real-time. In such cases, the following steps can be used to identify the cause of memory overload that has occurred in the past."}, {"name": "concurrency_workload_memory_usage_classification", "content": "Based on the memory usage information obtained from the query, the memory usage can be classified as follows: If dynamic used memory is large and dynamic used shared memory is small, it indicates that there is a high memory usage on threads and sessions. If dynamic used memory is large and dynamic used shared memory is similar, it indicates that there is a large dynamic memory usage on the global memory context. If only shared used memory is large, it indicates that there is a high usage of shared memory, which can be ignored. If other used memory is large, it is usually due to frequent memory allocation and deallocation during business execution, leading to excessive memory fragmentation."}, {"name": "concurrency_workload_slow_sql_execution", "content": "The SQL execution is slow and does not meet customer expectations and business requirements"}, {"name": "concurrency_workload_suboptimal_query_plan", "content": "The query plan for the slow SQL is suboptimal, leading to poor performance"}, {"name": "concurrency_workload_overall_performance_slow", "content": "The overall performance is slow and does not meet the customer's latency requirements or expectations. This can be caused by various reasons such as business-side issues, insufficient system resources, suboptimal usage of database kernel resources, concurrency issues, suboptimal database configuration, and non-optimal SQL."}, {"name": "concurrency_workload_high_cpu_usage", "content": "High CPU usage can cause performance issues in the database system."}, {"name": "concurrency_workload_high_IO", "content": "If the IO utilization is high or there are abnormal IO metrics such as high r await or high Vawalt, it may indicate IO issues. Possible causes include cache/raid configuration problems or disk throttling. To analyze the IO consumption of threads, you can use tools like pidstat or iotop. If the IO consumption is abnormal for TPLworker threads, it means that user SQL queries are consuming a lot of IO. You can use the lwtid from pg_thread_wait_status view to find the corresponding session information and optimize the queries to reduce IO consumption."}, {"name": "concurrency_workload_abnormal_persistent_events", "content": "Abnormal persistent events in the database can be categorized as STATS, UNUCX EVENT, LOXXEVENT, and IO BVENT. Identifying abnormal persistent events can be an effective way to diagnose overall performance slow query issues."}, {"name": "concurrency_workload_long_term_performance_degradation", "content": "Long-term performance degradation refers to a scenario where performance fluctuates significantly within a certain period of time (e.g., hours). To diagnose this issue, compare performance reports and investigate the following items: Top SQL, Top Wait Events, Load Profile, Cache/IO Stats, and Object Stats."}, {"name": "concurrency_workload_short_term_performance_fluctuation", "content": "Short-term performance fluctuation refers to a scenario where performance fluctuates at a finer granularity (e.g., seconds). This issue may not be captured by default performance views, but can be analyzed using the techniques described in the chapter on analyzing performance fluctuations in the overall performance slow query analysis section."}, {"name": "concurrency_workload_suboptimal_sql", "content": "Suboptimal SQL queries can negatively impact overall performance and potentially saturate the database's thread pool. Identifying suboptimal SQL queries is important for performance optimization."}, {"name": "concurrency_workload_high_cpu", "content": "If the CPU usage is high, it can cause overall performance degradation"}, {"name": "concurrency_workload_high_io", "content": "If the IO usage is high, it can cause overall performance degradation"}, {"name": "concurrency_workload_high_memory", "content": "If the memory usage is high, it can cause overall performance degradation"}, {"name": "concurrency_workload_abnormal_events", "content": "If there are abnormal events, such as concurrent updates, it can cause overall performance degradation"}, {"name": "concurrency_workload_performance_jitter", "content": "If there is performance jitter, it can cause overall performance degradation"}, {"name": "concurrency_workload_high_cpu", "content": "High CPU usage in the database can be caused by poorly optimized SQL queries."}, {"name": "concurrency_workload_high_cpu_user_statement", "content": "High CPU usage in the database can be caused by poorly optimized user SQL statements."}, {"name": "concurrency_workload_high_io", "content": "High IO can be caused by user statements that result in excessive physical reads. It can be identified by checking the 'n blocks fetched' and 'n blocks hit' fields in the dbe_pert_statement/dhe_pert_summary_statement views. If the difference between these two fields is high, it indicates a high number of physical reads. Additionally, the 'wait status' and 'wait event' fields in the pg_thread_wait_status view can be checked to see if there are any IO-related events or data file reads. The dhe_perf_local_active_session/gs_asp views can also be queried to check for records with Query events related to 'IO EVENT/DataFileRead' during a specific time period. Slow SQL queries with a high difference in 'n blocks fetched' and 'n blocks hit' fields or high data IO time can also indicate high IO. In the case of slow SQL, the 'details' field may contain information about the events causing the high IO."}, {"name": "concurrency_workload_performance_jitter", "content": "Performance jitter refers to fluctuations in performance over a period of time. It can be analyzed at different time scales."}, {"name": "concurrency_workload_concurrent_query_optimization", "content": "GaussDB supports optimizing complex query execution using operator concurrency when system CU, memory, and IO resources are sufficient."}, {"name": "concurrency_workload_high_memory_usage", "content": "If the database process memory usage is consistently high, it can indicate memory overload."}, {"name": "concurrency_workload_memory_overload", "content": "In some cases, memory overload can cause cluster environment restart, making it difficult to locate the cause of memory overload in real-time. In such cases, the following steps can be used to locate the cause of memory overload that has occurred in the past."}, {"name": "concurrency_workload_high_memory_usage", "content": "High memory usage can be caused by various reasons, including excessive memory fragmentation, delayed memory release, and other factors."}, {"name": "concurrency_workload_high_memory_usage", "content": "In the scenario of parallel decoding, if the reading log thread or decoding thread consumes too much memory, it can lead to insufficient memory and trigger memory error. The memory usage of ParallelDeeokeoispatcher or ParallelDecodelog is found to be relatively high."}, {"name": "concurrency_workload_high_memory_usage_parallel_decoding", "content": "In the scenario of parallel decoding, if the reading log thread or decoding thread consumes too much memory, it can lead to insufficient memory and trigger memory error. The memory usage of ParallelDeeokeoispatcher or ParallelDecodelog is found to be relatively high."}, {"name": "concurrency_workload_suboptimal_sql_plan", "content": "If the SQL plan chosen for the query is not optimal, it can cause slow SQL performance on partitioned tables"}, {"name": "concurrency_workload_high_cpu_usage", "content": "High CPU usage can be caused by the gaussdb process or certain SQL statements. It can be diagnosed by checking the CPU usage of the system and analyzing the WDR report."}, {"name": "concurrency_workload_high_IO", "content": "If the system shows high IO utilization, it can indicate potential performance issues. This can be observed through metrics such as %util in iostat, high r_await (usually greater than 3ms), or high w_await (usually greater than 3ms)."}, {"name": "concurrency_workload_high_memory_usage", "content": "If the memory usage of the database system is high, it can cause slow program execution."}, {"name": "concurrency_workload_suboptimal_database_usage", "content": "Suboptimal database usage can lead to performance degradation and inefficiency."}, {"name": "concurrency_workload_abnormal_wait_events", "content": "Abnormal wait events in the database can indicate performance issues"}, {"name": "concurrency_workload_long_term_performance_degradation", "content": "Long-term performance degradation refers to a scenario where the performance of the database fluctuates significantly over a certain period of time (hours). For example, the performance is normal from 8:00 to 9:00, but there is a significant performance fluctuation from 10:00 to 11:00. In this scenario, we can compare the WDR reports of the two time periods to identify any differences. The following aspects can be investigated: (1) Top SQL queries, (2) Top wait events, (3) Load profile, (4) Cache/IO statistics, (5) Object statistics."}, {"name": "concurrency_workload_short_term_performance_jitter", "content": "Short-term performance jitter refers to the situation where there are sudden fluctuations in performance at the second level. This is not adequately captured by the default one-hour interval of the WDR snapshot. It can be diagnosed by referring to the chapter on overall performance slow - analyzing performance jitter."}, {"name": "concurrency_workload_io_abnormality", "content": "This event indicates an IO abnormality. Possible causes include IO issues or inefficient IO usage due to business operations. Investigate and analyze further."}, {"name": "concurrency_workload_high_cpu_user_sql", "content": "If the high CPU usage is caused by the database process, it is usually due to poorly optimized SQL statements. This section focuses on CPU abnormalities caused by user statements."}, {"name": "concurrency_workload_high_io", "content": "High IO can be caused by user statements that result in excessive physical reads. It can be identified by checking the 'nblocks_fetched' and 'nblockshit' fields in the dbe_perf.statement/dbeperfsummary statement tables. If the difference between these two fields is high, it indicates a high number of physical reads."}, {"name": "concurrency_workload_high_memory_usage", "content": "If the database kernel has high memory usage, it can lead to various issues such as query errors and abnormal memory consumption on user sessions."}, {"name": "concurrency_workload_abnormal_wait_events", "content": "Abnormal wait events can cause overall slowness in the system. It is important to identify these wait events and analyze if they are causing performance issues. Common approaches to reduce abnormal wait events can be found in the 'Overall Performance Slow - Wait Event Analysis' chapter (Chapter 1.2)."}, {"name": "concurrency_workload_high_io", "content": "High IO can cause performance degradation. It is important to identify the tables or queries that are causing high IO and optimize them."}, {"name": "concurrency_workload_abnormal_wait_events", "content": "Abnormal wait events, including concurrent updates, can cause overall slowness in the system. It is important to identify these wait events and analyze if they are causing performance issues. Common approaches to reduce abnormal wait events can be found in the 'Overall Performance Slow - Wait Event Analysis' chapter (Chapter 1.2)."}, {"name": "concurrency_workload_concurrency_issues", "content": "Concurrency issues can cause performance degradation, such as increased response time, decreased TPS, or thread pool saturation."}, {"name": "concurrency_workload_concurrency_issues", "content": "Concurrency issues can cause performance degradation, such as increased response time, decreased TPS, or thread pool saturation."}, {"name": "concurrency_workload_concurrent_update_delete", "content": "If the business error is caused by concurrent UPDATE/DELETE operations on a partitioned table with row movement enabled, it can be resolved by disabling row movement or handling the business logic to avoid such conflicts."}, {"name": "concurrency_workload_concurrency_issues", "content": "Concurrency issues can cause increased latency, decreased TPS, or thread pool exhaustion. This is mainly caused by concurrent updates and resulting lock waits."}, {"name": "concurrency_workload_concurrent_updates", "content": "This event indicates concurrent updates. If there is a large number of these events, it may indicate a high level of concurrent updates causing overall business blocking. Use pg_thread_wait_status/dbe_perf.local_active_session/gs_asp to find the specific session_id causing the blockage."}, {"name": "io_disk_io_resource_contention", "content": "This piece of code checks for IO resource contention in the system. It does so by iterating through the IO utils of each device and checking if the maximum IO utils exceed the disk_ioutils_threshold. If there is contention, the function provides details on the device and the IO utils that exceed the threshold. It also suggests two possible causes of contention: competing processes outside the database and long transactions within the database. If there is contention, it is considered a root cause of the issue. If there is no contention, it is not a root cause."}, {"name": "io_disk_file_system_diagnostic_analysis", "content": "The code provided is diagnosing the usage and availability of file systems. \n\nThe variable `fs` stores the file systems retrieved using the `getfs()` function. \n`fs_info` is an empty string that will be used to store diagnostic information about the file systems. \n`flag_fs` is an integer variable initialized to 0 and will be used to count the number of file systems with issues. \n\nThe code then enters a loop where it iterates over each file system in `fs`. Within the loop, the code appends SQL queries to the `sql_fs` string. These queries collect information about the file system, such as its name (`fsmp`) and percentage of disk space used (`fspct`).\n\nThe code then proceeds to analyze each file system individually. If the file system's disk usage is between 80% and 95% and the amount of free space (`fsres`) is less than 500MB, a diagnostic message is added to `fs_info` indicating that the file system's usage is high and its free space is low. The `flag_fs` variable is incremented to indicate that an issue has been detected.\n\nSimilarly, if the file system's usage is between 80% and 95% and the free space is greater than 5GB, another diagnostic message is added to `fs_info` indicating that the file system's usage is high but its free space is sufficient. `flag_fs` is incremented again in this case.\n\nIf the file system's usage is equal to or greater than 95%, a diagnostic message is added to `fs_info` indicating that the file system's usage exceeds the critical threshold.\n\nFinally, if none of the above conditions are true, which means the file system's usage is below 80%, a diagnostic message is added to `fs_info` stating that the file system's usage is normal.\n\nIn summary, this code diagnoses the usage and availability of file systems and provides relevant diagnostic information based on pre-defined thresholds. The `sql_fs` and `fs_info` variables store information for further analysis and reporting. The `flag_fs` variable keeps track of the number of file systems with issues identified."}, {"name": "io_disk_disk_group_usage_diagnostic_analysis", "content": "The provided code appears to be a diagnostic script related to monitoring the usage of disk groups. The code iterates over a list called 'dg' and dynamically constructs a SQL query called 'sql_dg' by concatenating strings. The constructed query combines the names and percentages of disk groups ('dgname' and 'dgpct') using the \"union all\" clause.\n\nAfter constructing the SQL query, the code includes a series of conditional statements to analyze the disk group usage. If the percentage ('dgpct') is greater than 80 and less than 95, and the free space ('dgfree') is less than 2048, a diagnostic message is appended to the 'dg_info' string indicating that the disk group usage is high and the available space is low. The 'flag_dg' variable is incremented to indicate that a disk group exceeding the threshold has been identified.\n\nSimilarly, if the percentage is greater than 80 and less than 95, but the free space is greater than 10240, another diagnostic message is appended, indicating that the disk group usage is relatively high but the available space is sufficient. Again, 'flag_dg' is incremented.\n\nIf the percentage is equal to or greater than 95, a diagnostic message is appended to 'dg_info' indicating that the disk group usage is significantly exceeding the warning limit. 'flag_dg' is incremented accordingly.\n\nIf none of the above conditions are met, a message indicating normal disk group usage is appended to 'dg_info'.\n\nThe final line of the code trims off the trailing \"union all\" from the constructed SQL query.\n\nIn summary, this code analyzes the usage of disk groups and provides diagnostic messages based on defined thresholds and conditions. It iterates over a list of disk group information, constructs a SQL query, and appends diagnostic messages based on the calculated values."}, {"name": "io_disk_high_IO", "content": "If the IO utilization is high or there are abnormal IO metrics such as high r await or high Vawalt, it may indicate IO issues. Possible causes include cache/RAID configuration problems or disk throttling. To analyze the IO consumption of threads, you can use tools like pidstat or iotop. If the IO consumption is mainly caused by TPLworker threads, it means that user SQL queries are consuming a lot of IO. You can use the lwtid from pg_thread_wait_status to find the corresponding tid and sessionid, and then use the tid/sessionid to find the session information and specific queries from pg_stat_activity. To optimize the queries and reduce IO consumption, refer to the performance tuning chapter."}, {"name": "io_disk_abnormal_IO", "content": "If the IO utilization is high or there are abnormal IO metrics such as high r await or high Vawalt, it may indicate IO issues. Possible causes include cache/RAID configuration problems or disk throttling. To analyze the IO consumption of threads, you can use tools like pidstat or iotop. If the IO consumption is mainly caused by TPLworker threads, it means that user SQL queries are consuming a lot of IO. You can use the lwtid from pg_thread_wait_status to find the corresponding tid and sessionid, and then use the tid/sessionid to find the session information and specific queries from pg_stat_activity. To optimize the queries and reduce IO consumption, refer to the performance tuning chapter."}, {"name": "io_disk_abnormal_persistent_events", "content": "Abnormal persistent events in the database can impact overall performance. These events can be categorized as STATS, UNUCX EVENT, LOXXEVENT, and IO BVENT."}, {"name": "io_disk_high_io", "content": "If the IO usage is high, it can cause overall performance slowdown"}, {"name": "io_disk_high_io", "content": "High IO can be caused by user statements that result in excessive physical reads. It can be identified by checking the 'n blocks fetched' and 'n blocks hit' fields in the dbe_pert_statement/dhe_pert_summary_statement views. If the difference between these two fields is high, it indicates a high number of physical reads. Additionally, the 'wait status' and 'wait event' fields in the pg_thread_wait_status view can be checked to see if there are any IO-related events or data file reads. The dhe_perf_local_active_session/gs_asp views can also be queried to check for records with Query events related to 'IO EVENT/DataFileRead' during a specific time period. Slow SQL queries with a high difference in 'n blocks fetched' and 'n blocks hit' fields or high data IO time can also indicate high IO. In the case of slow SQL, the 'details' field may contain information about the events causing the high IO."}, {"name": "io_disk_high_IO", "content": "If the IO utilization is high or there are abnormal IO metrics such as high r await or high Vawalt, it may indicate IO issues. Possible causes include cache/raid configuration problems or disk throttling. To analyze the IO consumption of threads, you can use tools like pidstat or iotop. If the IO consumption is abnormal for TPLworker threads, it means that user SQL queries are consuming a lot of IO. You can use the lwtid from pg_thread_wait_status view to find the corresponding session information and optimize the queries to reduce IO consumption."}, {"name": "io_disk_abnormal_persistent_events", "content": "Abnormal persistent events in the database can be categorized as STATS, UNUCX EVENT, LOXXEVENT, and IO BVENT. Identifying abnormal persistent events can be an effective way to diagnose overall performance slow query issues."}, {"name": "io_disk_high_io", "content": "If the IO usage is high, it can cause overall performance degradation"}, {"name": "io_disk_high_io", "content": "High IO can be caused by user statements that result in excessive physical reads. It can be identified by checking the 'n blocks fetched' and 'n blocks hit' fields in the dbe_pert_statement/dhe_pert_summary_statement views. If the difference between these two fields is high, it indicates a high number of physical reads. Additionally, the 'wait status' and 'wait event' fields in the pg_thread_wait_status view can be checked to see if there are any IO-related events or data file reads. The dhe_perf_local_active_session/gs_asp views can also be queried to check for records with Query events related to 'IO EVENT/DataFileRead' during a specific time period. Slow SQL queries with a high difference in 'n blocks fetched' and 'n blocks hit' fields or high data IO time can also indicate high IO. In the case of slow SQL, the 'details' field may contain information about the events causing the high IO."}, {"name": "io_disk_high_IO", "content": "If the system shows high IO utilization, it can indicate potential performance issues. This can be observed through metrics such as %util in iostat, high r_await (usually greater than 3ms), or high w_await (usually greater than 3ms)."}, {"name": "io_disk_io_abnormality", "content": "This event indicates an IO abnormality. Possible causes include IO issues or inefficient IO usage due to business operations. Investigate and analyze further."}, {"name": "io_disk_high_io", "content": "High IO can be caused by user statements that result in excessive physical reads. It can be identified by checking the 'nblocks_fetched' and 'nblockshit' fields in the dbe_perf.statement/dbeperfsummary statement tables. If the difference between these two fields is high, it indicates a high number of physical reads."}, {"name": "io_disk_high_io", "content": "High IO can cause performance degradation. It is important to identify the tables or queries that are causing high IO and optimize them."}, {"name": "write_events_update_large_data", "content": "This function checks whether a table has a large number of tuples updated. If the number of updated tuples is greater than or equal to the specified threshold, it is considered a root cause. The function then provides details on the number of updated tuples and suggests making adjustments to the business. If the number of updated tuples is not above the threshold or if there is no plan parse information available, it is not a root cause."}, {"name": "write_events_insert_large_data", "content": "This function checks whether a query related table has a large number of inserted tuples. If the number of inserted tuples is greater than or equal to the specified threshold (stored in the variable \"inserted_tuples_threshold\"), it is considered a root cause. The function then calculates the ratio of inserted tuples to live tuples and provides a suggestion to make adjustments to the business. If the number of inserted tuples is less than the threshold, the function checks for insert operators and if any of them have a large number of rows inserted (greater than the threshold), it is considered a root cause and a suggestion is provided. If neither of these conditions are met, it is not a root cause."}, {"name": "write_events_delete_large_data", "content": "This function checks whether a table has too many tuples to be deleted. If the number of deleted tuples is greater than or equal to the specified threshold, it is considered a root cause and will be deleted in the future. If the number of deleted tuples is less than the threshold, the function checks whether there is a delete operation on a table with a large number of tuples. If so, it is also considered a root cause and the suggestion is to make adjustments to the business. If neither condition is met, it is not a root cause."}, {"name": "memory_accumulation", "content": "If temporary memory is not released in a timely manner during the execution of SQL statements, it can lead to memory accumulation."}, {"name": "memory_accumulation", "content": "If temporary memory is not released in a timely manner during the execution of SQL statements, it can lead to memory accumulation."}, {"name": "memory_accumulation", "content": "High memory usage in the database process can be caused by memory accumulation, such as temporary memory not being released in a timely manner or frequent memory allocation and deallocation"}, {"name": "memory_resource_contention", "content": "This function checks whether there is contention for memory resources by other processes outside the database. If the maximum system memory usage exceeds the detection threshold specified in the variable \"mem_usage_threshold\", the function sets the \"system_mem_contention\" key in the \"detail\" dictionary to indicate that the current system memory usage is significant. If the \"system_mem_contention\" key exists in the \"detail\" dictionary, the function suggests checking for external processes that may be consuming resources. If the function returns True, it indicates that memory resource contention is a root cause of the problem. If the function returns False, it means that memory resource contention is not a root cause."}, {"name": "memory_Memory_usage_analysis_diagnosis", "content": "The code lines are analyzing and diagnosing the memory usage of a system. The code first retrieves the memory information using the \"getmem\" function. Then, it fetches the long-term memory information using the \"getltmem\" function with specific parameters. \n\nNext, the code initializes variables to store information about memory and swap usage. There are also flag variables that indicate whether there are any memory or swap issues.\n\nThe code then constructs a SQL query to retrieve specific memory information for each record obtained from the \"getmem\" function. Based on the retrieved information, the code analyzes the memory usage and assigns appropriate diagnostic messages to the \"mem_info\" variable. \n\nIf the physical memory usage exceeds 90% and the free memory is below 200M and above 100M, it indicates that the physical memory usage is high and the available memory is low, which may pose performance risks. Similarly, if the physical memory usage exceeds 90% and the free memory is below 100M, it suggests a high memory usage and a significant performance risk.\n\nIf the physical memory usage exceeds 20% of the recent average, it is recommended to perform further checks. \n\nThe code also checks the swap usage. If the swap usage is above 50% and below 80%, it indicates a high swap usage and suggests further investigation. If the swap usage exceeds 80%, it suggests a high swap usage and recommends immediate investigation.\n\nAfter analyzing each record, the code appends the diagnostic messages for memory and swap usage to the respective variables.\n\nFinally, the code removes the last \"union all\" from the constructed SQL query.\n\nIn conclusion, the code analyzes the memory and swap usage of a system and generates diagnostic messages based on the specific threshold values and recent average usage. These messages provide insights into any potential memory and swap issues that may affect the system's performance."}, {"name": "memory_full", "content": "If the memory is full, it can cause slow program execution. To diagnose this issue, we need to identify the process with abnormal memory usage. In this case, we only consider the abnormal memory usage of the database process. For other processes, they are not representative and will not be described in detail here. To analyze the high memory usage of the database process, please refer to the relevant chapter on overall performance analysis."}, {"name": "high_memory", "content": "If the memory usage is high, it can cause overall performance slowdown"}, {"name": "high_memory_usage", "content": "High memory usage in the database can lead to performance issues. It is important to analyze and identify the specific areas of memory consumption."}, {"name": "high_memory_usage", "content": "If the database process memory usage is consistently high, it can indicate memory overload."}, {"name": "high_concurrency_memory_usage", "content": "If the number of connections to the server is too high, it can lead to high memory usage."}, {"name": "high_memory_usage_sql", "content": "Some SQL statements may have high memory usage, leading to temporary memory spikes."}, {"name": "high_memory_usage", "content": "If the database process memory usage is consistently high, it can indicate memory overload."}, {"name": "memory_overload", "content": "If the memory usage of the database process is high, it can be caused by memory accumulation or other reasons"}, {"name": "memory_overload", "content": "In some cases, memory overload can cause cluster restarts, making it difficult to locate the cause of memory overload in real-time. In such cases, the following steps can be used to identify the cause of memory overload that has occurred in the past."}, {"name": "memory_usage_classification", "content": "Based on the memory usage information obtained from the query, the memory usage can be classified as follows: If dynamic used memory is large and dynamic used shared memory is small, it indicates that there is a high memory usage on threads and sessions. If dynamic used memory is large and dynamic used shared memory is similar, it indicates that there is a large dynamic memory usage on the global memory context. If only shared used memory is large, it indicates that there is a high usage of shared memory, which can be ignored. If other used memory is large, it is usually due to frequent memory allocation and deallocation during business execution, leading to excessive memory fragmentation."}, {"name": "high_memory", "content": "If the memory usage is high, it can cause overall performance degradation"}, {"name": "high_memory_usage", "content": "If the database process memory usage is consistently high, it can indicate memory overload."}, {"name": "memory_overload", "content": "In some cases, memory overload can cause cluster environment restart, making it difficult to locate the cause of memory overload in real-time. In such cases, the following steps can be used to locate the cause of memory overload that has occurred in the past."}, {"name": "high_memory_usage", "content": "High memory usage can be caused by various reasons, including excessive memory fragmentation, delayed memory release, and other factors."}, {"name": "high_memory_usage", "content": "In the scenario of parallel decoding, if the reading log thread or decoding thread consumes too much memory, it can lead to insufficient memory and trigger memory error. The memory usage of ParallelDeeokeoispatcher or ParallelDecodelog is found to be relatively high."}, {"name": "high_memory_usage_parallel_decoding", "content": "In the scenario of parallel decoding, if the reading log thread or decoding thread consumes too much memory, it can lead to insufficient memory and trigger memory error. The memory usage of ParallelDeeokeoispatcher or ParallelDecodelog is found to be relatively high."}, {"name": "high_memory_usage", "content": "If the memory usage of the database system is high, it can cause slow program execution."}, {"name": "high_memory_usage", "content": "If the database kernel has high memory usage, it can lead to various issues such as query errors and abnormal memory consumption on user sessions."}, {"name": "recovery_abnormal_network_status", "content": "This piece of code checks for abnormal network status by analyzing packet loss rate and bandwidth usage. It first checks the receive and transmit drop rates for each device and appends any abnormal rates to a list of details. It then checks the bandwidth usage for each device and appends any abnormal rates to the same list of details. If any abnormal rates are found, the function sets the detail and suggestion attributes accordingly and returns True, indicating that abnormal network status is a root cause. If no abnormal rates are found, the function returns False, indicating that abnormal network status is not a root cause. The thresholds for abnormal packet loss rate and network bandwidth usage are obtained from the monitoring module."}, {"name": "recovery_network_unreachable", "content": "One common cause of network issues is when the database server is unable to establish a connection with the application server."}, {"name": "recovery_network_unreachable", "content": "One common cause of network issues is when the database server is unable to establish a connection with the application server"}, {"name": "abnormal_disaster_recovery_setup_process", "content": "The disaster recovery setup process is abnormal, which may cause issues in cross-region disaster recovery"}, {"name": "recovery_abnormal_failover_process", "content": "The failover process from standby to primary in a disaster recovery setup is abnormal"}, {"name": "recovery_abnormal_wltchover_process", "content": "The planned wltchover process is abnormal"}, {"name": "abnormal_disaster_recovery_performance_metrics", "content": "The performance metrics of the disaster recovery setup are abnormal"}, {"name": "disaster_recovery_process_abnormal", "content": "The disaster recovery setup process returns failure or times out"}, {"name": "recovery_failover_abnormal", "content": "The failover process of the disaster recovery to the primary cluster is abnormal, with some nodes not participating in the failover"}, {"name": "abnormal_disaster_recovery_status", "content": "The cluster-level PO value keeps increasing during the low business period, indicating abnormal disaster recovery. The ON status of the disaster recovery cluster shows 'Need repair (Disconnected)'. The QLACBT node in the disaster recovery cluster is faulty, and the instance status on this node shows 'Deleted' for CX, 'Unknown' for DN and CTU, and 'Main Standby Need repair (Connecting)' for some primary standby instances."}, {"name": "cpu_resource_contention", "content": "This function checks whether there is contention for CPU resources by other processes outside the database. If the maximum CPU usage of these processes exceeds the threshold specified in the variable \"cpu_usage_threshold\", the function sets the \"system_cpu_contention\" key in the \"detail\" dictionary to indicate the current user CPU usage. If this key is set, the function suggests handling exception processes in the system as a solution. If the \"system_cpu_contention\" key is not set, this issue is not a root cause."}, {"name": "cpu_os_resource_contention", "content": "This function checks for a potential issue where other processes outside the database may be occupying too many handle resources. If the system file descriptor (fds) occupation rate exceeds the detection threshold, it is considered a root cause and the function returns a boolean value of True. The system fds occupation rate is recorded in the diagnosis report along with a suggestion to determine whether the handle resource is occupied by the database or other processes. If the system fds occupation rate is below the tuple_number_threshold, it is not a root cause and the function returns a boolean value of False."}, {"name": "cpu_CPU_analysis_and_diagnostics", "content": "The code provided is analyzing the CPU workload and providing diagnostics based on certain conditions. \n\nFirst, the code retrieves CPU information using the \"getcpu\" function. It initializes variables \"sql_cpu\", \"flag_cpu\", and \"cpuinfo\". \n\nThen, it enters a loop to process each CPU resource. It concatenates SQL queries using the values from each resource, which will be used for further analysis. \n\nThe code then checks the value of the \"r\" attribute in each resource. If it is less than or equal to the variable \"cpun\" (representing the number of CPU threads), it indicates that the CPU load is not high. However, if it is greater than \"cpun\" but less than or equal to \"cpun\" multiplied by 2, it suggests that the CPU load is relatively high. If the value of \"r\" exceeds \"cpun\" multiplied by 2, it indicates a high CPU load with potential risks. The variable \"flag_cpu\" is incremented accordingly to keep track of the CPU load status.\n\nThe code then examines the value of the \"us\" attribute (representing CPU usage). If it is less than 20, it suggests that the CPU usage is not high. If it is between 20 and 80 (inclusive), it indicates normal CPU usage. If it is between 80 and 95 (inclusive), it suggests relatively high CPU usage. If the value exceeds 95 and the \"r\" value is greater than \"cpun\" multiplied by 2, it indicates a high CPU usage with a potential bottleneck. Otherwise, it concludes that the CPU is currently not experiencing performance bottlenecks.\n\nNext, the code evaluates the value of the \"sys\" attribute (representing system CPU usage). If it is less than 15, it suggests normal system CPU usage. If it is between 15 and 30 (inclusive), it indicates relatively high usage and requires attention to potential system issues. If it exceeds 30, it suggests significantly high system CPU usage, indicating the presence of serious vulnerabilities.\n\nBy analyzing the CPU information and applying various conditions, the code provides diagnostic information in the variable \"cpuinfo\". The variable \"flag_cpu\" keeps track of the number of identified CPU load issues."}, {"name": "high_cpu_usage", "content": "High CPU usage can cause slow SL execution and impact overall system performance"}, {"name": "high_cpu_usage_flame_graph", "content": "Flame graph analysis can be used to identify functions with high CPU usage and potential performance issues"}, {"name": "high_cpu_usage", "content": "High CPU usage can cause performance issues in the database system"}, {"name": "high_cpu", "content": "If the CPU usage is high, it can cause overall performance slowdown"}, {"name": "high_cpu", "content": "High CPU usage in the database can be caused by poorly optimized SQL queries."}, {"name": "high_cpu_usage", "content": "High CPU usage can cause performance issues in the database system."}, {"name": "high_cpu", "content": "If the CPU usage is high, it can cause overall performance degradation"}, {"name": "high_cpu", "content": "High CPU usage in the database can be caused by poorly optimized SQL queries."}, {"name": "high_cpu_user_statement", "content": "High CPU usage in the database can be caused by poorly optimized user SQL statements."}, {"name": "high_cpu_usage", "content": "High CPU usage can be caused by the gaussdb process or certain SQL statements. It can be diagnosed by checking the CPU usage of the system and analyzing the WDR report."}, {"name": "high_cpu_user_sql", "content": "If the high CPU usage is caused by the database process, it is usually due to poorly optimized SQL statements. This section focuses on CPU abnormalities caused by user statements."}, {"name": "query_operator_operator_penalty_parameters", "content": "The operator penalty parameters control the cost of certain operators in the query plan. By disabling these parameters, the optimizer will try to avoid selecting these operators in the execution plan."}, {"name": "query_operator_operator_cost_parameters", "content": "The operator cost parameters control the relative size of the operator cost calculation, which can accurately control the operator selection potential."}, {"name": "query_operator_operator_penalty_parameters", "content": "The operator penalty parameters control the cost of certain operators in the query plan. By disabling these parameters, the optimizer will try to avoid selecting these operators in the execution plan."}, {"name": "query_operator_operator_cost_parameters", "content": "The operator cost parameters control the relative size of the operator cost calculation, which can accurately control the operator selection potential."}, {"name": "query_operator_poor_join_performance", "content": "This code diagnoses poor performance in join operations. There are four main situations that can cause poor join performance: 1) when the GUC parameter 'enable_hashjoin' is set to 'off', which can result in the optimizer choosing NestLoop or other join operators even when HashJoin would be more suitable; 2) when the optimizer incorrectly chooses the NestLoop operator, even when 'set_hashjoin' is on; 3) when the join operation involves a large amount of data, which can lead to high execution costs; and 4) when the cost of the join operator is expensive. \n\nIn general, NestLoop is suitable when the inner table has a suitable index or when the tuple of the outer table is small (less than 10000), while HashJoin is suitable for tables with large amounts of data (more than 10000), although index will reduce HashJoin performance to a certain extent. Note that HashJoin requires high memory consumption.\n\nThe code checks for abnormal NestLoop, HashJoin, and MergeJoin operators, and identifies inappropriate join nodes based on the number of rows and cost rate. It also provides suggestions for optimization, such as setting 'enable_hashjoin' to 'on', optimizing SQL structure to reduce JOIN cost, and using temporary tables to filter data. \n\nIf the code finds any poor join performance, it is considered a root cause of the problem. Otherwise, it is not a root cause."}, {"name": "query_operator_complex_execution_plan", "content": "This is a function that checks for complex execution plans in SQL statements. The function identifies two cases that may cause complex execution plans: (1) a large number of join or group operations, and (2) a very complex execution plan based on its height. If the function identifies either of these cases, it sets the corresponding details and suggestions for the user. If the number of join operators exceeds the \"complex_operator_threshold\" or the plan height exceeds the \"plan_height_threshold\", the function considers it a root cause of the problem. Otherwise, it is not a root cause."}, {"name": "query_operator_poor_aggregation_performance", "content": "This function diagnoses poor aggregation performance in SQL queries. It identifies four potential root causes: (1) when the GUC parameter 'enable_hashagg' is set to 'off', resulting in a higher tendency to use the GroupAgg operator; (2) when the query includes scenarios like 'count(distinct col)', which makes HashAgg unavailable; (3) when the cost of the GroupAgg operator is expensive; and (4) when the cost of the HashAgg operator is expensive. The code checks for these conditions and provides detailed information and suggestions for each potential root cause. If none of these conditions are met, poor aggregation performance is not a root cause."}, {"name": "query_operator_abnormal_sql_structure", "content": "This function checks for a specific issue in the SQL structure that can lead to poor performance. If the rewritten SQL information is present, it indicates that the SQL structure is abnormal and can be a root cause of performance issues. The function provides a detailed description of the issue and suggests a solution to address it. If the rewritten SQL information is not present, it is not a root cause of the performance issue."}, {"name": "query_operator_poor_index_filtering", "content": "The query may have poor index filtering, leading to slow performance."}, {"name": "query_operator_slow_sql_execution", "content": "The SQL execution is slow and does not meet customer expectations and business requirements"}, {"name": "query_operator_poor_query_plan", "content": "The query plan is not optimal, leading to slow SQL execution"}, {"name": "query_operator_suboptimal_query_plan", "content": "The query plan is not optimal, leading to slow SQL execution"}, {"name": "query_operator_suboptimal_sql", "content": "Suboptimal SQL queries can negatively impact overall performance, potentially leading to thread pool saturation and other severe performance issues."}, {"name": "query_operator_slow_sql_execution", "content": "The SQL execution is slow and does not meet customer expectations and business requirements"}, {"name": "query_operator_suboptimal_query_plan", "content": "The query plan for the slow SQL is suboptimal, leading to poor performance"}, {"name": "database_configuration", "content": "Database configuration can affect performance. Common configuration issues include shared buffers being too small, insufficient work mem for sorting operations, and thread pool worker parameters being set too small."}, {"name": "database_configuration", "content": "Database configuration can affect performance. Common configuration issues include: shared buffers set too small, insufficient work_mem for sorting operators, and thread pool worker parameters set too small."}, {"name": "database_configuration", "content": "The database configuration may not be optimal, leading to performance issues. Common configuration issues include shared_buffers being too small, work_mem being too small for sorting operations, and thread_pool_attr being set too small."}, {"name": "configuration_work_mem", "content": "The work_mem parameter determines the amount of memory used for internal sorting operations and hash tables before writing to temporary disk files. It is used in operations such as ORDER BY, DISTINCT, and merge joins."}, {"name": "configuration_maintenance_work_mem", "content": "The maintenance_work_mem parameter determines the maximum amount of memory that can be used for maintenance operations such as VACUUM and CREATE INDEX. It affects the efficiency of these maintenance operations."}, {"name": "configuration_work_mem", "content": "The work_mem parameter determines the amount of memory used for internal sorting operations and hash tables before writing to temporary disk files. It is used in operations such as ORDER BY, DISTINCT, and merge joins."}, {"name": "configuration_maintenance_work_mem", "content": "The maintenance_work_mem parameter determines the maximum amount of memory that can be used for maintenance operations such as VACUUM and CREATE INDEX. It affects the efficiency of these maintenance operations."}, {"name": "configuration_quick_recovery", "content": "There is no fixed method for quick recovery as it depends on the specific problem. In some cases, coordination with the business side may be required for resolution."}, {"name": "configuration_quick_recovery", "content": "There is no fixed method for quick recovery as it depends on the specific problem. Sometimes it may require coordination with the business side to resolve the issue."}, {"name": "configuration_quick_recovery", "content": "There is no fixed method for quick recovery as it depends on the specific problem. Sometimes, coordination with the business side may be required for resolution."}, {"name": "unused_and_redundant_index", "content": "This function checks for the presence of unused or redundant indexes in a table that is related to a query. Unused indexes are those that have not been used for a long time, while redundant indexes are those that are not needed for the query. If the table is not large or there are no unused or redundant indexes, or if the query involves a select operation, then the function is not a root cause. Otherwise, the function identifies the unused and redundant indexes and provides suggestions to clean them up. The threshold for identifying unused indexes is not specified in the code."}, {"name": "too_many_index", "content": "This function checks for the presence of too many indexes in a table, which can negatively impact the performance of insert and update operations. If the table structure is not available or the select type is not appropriate, this is not a root cause. If there are a large number of indexes in the table, the function identifies the related tables and provides details on the number of indexes. In this case, the function is a root cause and suggests that too many indexes can slow down insert, delete, and update statements. The threshold for the number of indexes is determined by the variable \"index_number_threshold\"."}, {"name": "missing_index", "content": "This function checks for the presence of a required index using a workload-index-recommend interface. If the recommended index information is available, it indicates that a required index is missing and provides a suggestion for the recommended index. If the information is not available, it is not a root cause for the issue."}, {"name": "index_not_used", "content": "If the query plan does not utilize an index, it may indicate a performance issue"}, {"name": "index_not_used", "content": "If the index plan is not used, it may be due to invalid statistics, index invalidation, implicit type conversion, or pattern matching filter conditions."}, {"name": "index_not_used", "content": "If the index plan is not used, it may be caused by invalid statistics, index invalidation, implicit type conversion, or pattern matching filter conditions."}, {"name": "database_bottleneck", "content": "To determine if the bottleneck is on the database side, check the CPU usage of the host where the database is located, relevant views in the database, or related metrics on OPS. If there are very few active sessions in the database, it is highly likely that the database throughput cannot increase."}, {"name": "business_bottleneck", "content": "If the database side does not perceive obvious business pressure, or the pressure is not large enough and resource consumption is very low (e.g., CPU usage is less than IO%, the number of active sessions is single-digit), it is recommended to investigate on the business side. Common causes may include: application server resource exhaustion (insufficient CPU/IO/memory), high network latency between application server and database, slow processing of query results on the application server, resulting in slow transmission of SQL statements within transactions to the database, etc."}, {"name": "bottleneck_database_throttling", "content": "This event indicates that the database has flow control enabled to ensure RTO (Recovery Time Objective). It is recommended to consider disabling flow control during performance testing if it significantly affects performance."}, {"name": "concurrency_workload_workload_contention", "content": "This code is designed to diagnose workload contention issues in a database system. The function checks for several potential causes of contention, including abnormal CPU and memory resource usage, insufficient space in the database data directory, and excessive connections or thread pool usage. If any of these issues are detected, the function provides a detailed report of the problem and suggests potential solutions. If no issues are found, the function returns \"not a root cause\"."}, {"name": "concurrency_workload_database_wait_event", "content": "This function checks if there is a wait event in the database. If there is a wait event, it retrieves the wait status and wait event information and stores it in the detail dictionary. If the detail dictionary already has wait event information, it suggests that there is no root cause for the issue. Otherwise, it suggests that the wait event may be a root cause for the issue. If there is no wait event information, it suggests that there is no root cause for the issue. Therefore, the presence of wait event information is a root cause for the issue, while the absence of wait event information is not a root cause."}, {"name": "concurrency_workload_CPU_analysis_and_diagnostics", "content": "The code provided is analyzing the CPU workload and providing diagnostics based on certain conditions. \n\nFirst, the code retrieves CPU information using the \"getcpu\" function. It initializes variables \"sql_cpu\", \"flag_cpu\", and \"cpuinfo\". \n\nThen, it enters a loop to process each CPU resource. It concatenates SQL queries using the values from each resource, which will be used for further analysis. \n\nThe code then checks the value of the \"r\" attribute in each resource. If it is less than or equal to the variable \"cpun\" (representing the number of CPU threads), it indicates that the CPU load is not high. However, if it is greater than \"cpun\" but less than or equal to \"cpun\" multiplied by 2, it suggests that the CPU load is relatively high. If the value of \"r\" exceeds \"cpun\" multiplied by 2, it indicates a high CPU load with potential risks. The variable \"flag_cpu\" is incremented accordingly to keep track of the CPU load status.\n\nThe code then examines the value of the \"us\" attribute (representing CPU usage). If it is less than 20, it suggests that the CPU usage is not high. If it is between 20 and 80 (inclusive), it indicates normal CPU usage. If it is between 80 and 95 (inclusive), it suggests relatively high CPU usage. If the value exceeds 95 and the \"r\" value is greater than \"cpun\" multiplied by 2, it indicates a high CPU usage with a potential bottleneck. Otherwise, it concludes that the CPU is currently not experiencing performance bottlenecks.\n\nNext, the code evaluates the value of the \"sys\" attribute (representing system CPU usage). If it is less than 15, it suggests normal system CPU usage. If it is between 15 and 30 (inclusive), it indicates relatively high usage and requires attention to potential system issues. If it exceeds 30, it suggests significantly high system CPU usage, indicating the presence of serious vulnerabilities.\n\nBy analyzing the CPU information and applying various conditions, the code provides diagnostic information in the variable \"cpuinfo\". The variable \"flag_cpu\" keeps track of the number of identified CPU load issues."}, {"name": "concurrency_workload_Memory_usage_analysis_diagnosis", "content": "The code lines are analyzing and diagnosing the memory usage of a system. The code first retrieves the memory information using the \"getmem\" function. Then, it fetches the long-term memory information using the \"getltmem\" function with specific parameters. \n\nNext, the code initializes variables to store information about memory and swap usage. There are also flag variables that indicate whether there are any memory or swap issues.\n\nThe code then constructs a SQL query to retrieve specific memory information for each record obtained from the \"getmem\" function. Based on the retrieved information, the code analyzes the memory usage and assigns appropriate diagnostic messages to the \"mem_info\" variable. \n\nIf the physical memory usage exceeds 90% and the free memory is below 200M and above 100M, it indicates that the physical memory usage is high and the available memory is low, which may pose performance risks. Similarly, if the physical memory usage exceeds 90% and the free memory is below 100M, it suggests a high memory usage and a significant performance risk.\n\nIf the physical memory usage exceeds 20% of the recent average, it is recommended to perform further checks. \n\nThe code also checks the swap usage. If the swap usage is above 50% and below 80%, it indicates a high swap usage and suggests further investigation. If the swap usage exceeds 80%, it suggests a high swap usage and recommends immediate investigation.\n\nAfter analyzing each record, the code appends the diagnostic messages for memory and swap usage to the respective variables.\n\nFinally, the code removes the last \"union all\" from the constructed SQL query.\n\nIn conclusion, the code analyzes the memory and swap usage of a system and generates diagnostic messages based on the specific threshold values and recent average usage. These messages provide insights into any potential memory and swap issues that may affect the system's performance."}, {"name": "concurrency_workload_file_system_diagnostic_analysis", "content": "The code provided is diagnosing the usage and availability of file systems. \n\nThe variable `fs` stores the file systems retrieved using the `getfs()` function. \n`fs_info` is an empty string that will be used to store diagnostic information about the file systems. \n`flag_fs` is an integer variable initialized to 0 and will be used to count the number of file systems with issues. \n\nThe code then enters a loop where it iterates over each file system in `fs`. Within the loop, the code appends SQL queries to the `sql_fs` string. These queries collect information about the file system, such as its name (`fsmp`) and percentage of disk space used (`fspct`).\n\nThe code then proceeds to analyze each file system individually. If the file system's disk usage is between 80% and 95% and the amount of free space (`fsres`) is less than 500MB, a diagnostic message is added to `fs_info` indicating that the file system's usage is high and its free space is low. The `flag_fs` variable is incremented to indicate that an issue has been detected.\n\nSimilarly, if the file system's usage is between 80% and 95% and the free space is greater than 5GB, another diagnostic message is added to `fs_info` indicating that the file system's usage is high but its free space is sufficient. `flag_fs` is incremented again in this case.\n\nIf the file system's usage is equal to or greater than 95%, a diagnostic message is added to `fs_info` indicating that the file system's usage exceeds the critical threshold.\n\nFinally, if none of the above conditions are true, which means the file system's usage is below 80%, a diagnostic message is added to `fs_info` stating that the file system's usage is normal.\n\nIn summary, this code diagnoses the usage and availability of file systems and provides relevant diagnostic information based on pre-defined thresholds. The `sql_fs` and `fs_info` variables store information for further analysis and reporting. The `flag_fs` variable keeps track of the number of file systems with issues identified."}, {"name": "concurrency_workload_disk_group_usage_diagnostic_analysis", "content": "The provided code appears to be a diagnostic script related to monitoring the usage of disk groups. The code iterates over a list called 'dg' and dynamically constructs a SQL query called 'sql_dg' by concatenating strings. The constructed query combines the names and percentages of disk groups ('dgname' and 'dgpct') using the \"union all\" clause.\n\nAfter constructing the SQL query, the code includes a series of conditional statements to analyze the disk group usage. If the percentage ('dgpct') is greater than 80 and less than 95, and the free space ('dgfree') is less than 2048, a diagnostic message is appended to the 'dg_info' string indicating that the disk group usage is high and the available space is low. The 'flag_dg' variable is incremented to indicate that a disk group exceeding the threshold has been identified.\n\nSimilarly, if the percentage is greater than 80 and less than 95, but the free space is greater than 10240, another diagnostic message is appended, indicating that the disk group usage is relatively high but the available space is sufficient. Again, 'flag_dg' is incremented.\n\nIf the percentage is equal to or greater than 95, a diagnostic message is appended to 'dg_info' indicating that the disk group usage is significantly exceeding the warning limit. 'flag_dg' is incremented accordingly.\n\nIf none of the above conditions are met, a message indicating normal disk group usage is appended to 'dg_info'.\n\nThe final line of the code trims off the trailing \"union all\" from the constructed SQL query.\n\nIn summary, this code analyzes the usage of disk groups and provides diagnostic messages based on defined thresholds and conditions. It iterates over a list of disk group information, constructs a SQL query, and appends diagnostic messages based on the calculated values."}, {"name": "concurrency_workload_session_diagnostic_analysis", "content": "The function retrieves session information from the database. It starts by initializing the variables for session percentage (sesspct), session information (sess_info), and a flag for session (flag_sess). \n\nNext, it iterates through each element in sesspct and constructs a SQL query based on the values retrieved. It also checks if the session percentage is above 90%. If it is, a diagnostic message is added to sess_info indicating that the session percentage is too high and requires attention. Additionally, the flag_sess variable is incremented. If the session percentage is below or equal to 90%, a different diagnostic message is added to sess_info indicating that the session percentage is normal.\n\nThe constructed SQL query is then truncated to remove the trailing \"union all\" statement.\n\nOverall, this code performs a diagnostic analysis on session information, checking for high session percentages and providing relevant diagnostic messages."}, {"name": "concurrency_workload_high_cpu_usage", "content": "High CPU usage can cause slow SL execution and impact overall system performance"}, {"name": "concurrency_workload_high_cpu_usage_flame_graph", "content": "Flame graph analysis can be used to identify functions with high CPU usage and potential performance issues"}, {"name": "concurrency_workload_slow_overall_performance", "content": "The overall performance of the system is slow, causing high latency for business interfaces or not meeting customer expectations"}, {"name": "concurrency_workload_high_cpu_usage", "content": "High CPU usage can cause performance issues in the database system"}, {"name": "concurrency_workload_high_IO", "content": "If the IO utilization is high or there are abnormal IO metrics such as high r await or high Vawalt, it may indicate IO issues. Possible causes include cache/RAID configuration problems or disk throttling. To analyze the IO consumption of threads, you can use tools like pidstat or iotop. If the IO consumption is mainly caused by TPLworker threads, it means that user SQL queries are consuming a lot of IO. You can use the lwtid from pg_thread_wait_status to find the corresponding tid and sessionid, and then use the tid/sessionid to find the session information and specific queries from pg_stat_activity. To optimize the queries and reduce IO consumption, refer to the performance tuning chapter."}, {"name": "concurrency_workload_abnormal_IO", "content": "If the IO utilization is high or there are abnormal IO metrics such as high r await or high Vawalt, it may indicate IO issues. Possible causes include cache/RAID configuration problems or disk throttling. To analyze the IO consumption of threads, you can use tools like pidstat or iotop. If the IO consumption is mainly caused by TPLworker threads, it means that user SQL queries are consuming a lot of IO. You can use the lwtid from pg_thread_wait_status to find the corresponding tid and sessionid, and then use the tid/sessionid to find the session information and specific queries from pg_stat_activity. To optimize the queries and reduce IO consumption, refer to the performance tuning chapter."}, {"name": "concurrency_workload_memory_full", "content": "If the memory is full, it can cause slow program execution. To diagnose this issue, we need to identify the process with abnormal memory usage. In this case, we only consider the abnormal memory usage of the database process. For other processes, they are not representative and will not be described in detail here. To analyze the high memory usage of the database process, please refer to the relevant chapter on overall performance analysis."}, {"name": "concurrency_workload_abnormal_persistent_events", "content": "Abnormal persistent events in the database can impact overall performance. These events can be categorized as STATS, UNUCX EVENT, LOXXEVENT, and IO BVENT."}, {"name": "concurrency_workload_long_term_performance_degradation", "content": "Long-term performance degradation refers to a scenario where performance fluctuates over a certain period of time (e.g., hours). This can be identified by comparing performance reports from different time periods and analyzing differences in metrics such as top SQL, top wait events, load profile, cache/IO stats, and object stats."}, {"name": "concurrency_workload_short_term_performance_fluctuation", "content": "Short-term performance fluctuation refers to performance fluctuations that occur within a short period of time (e.g., seconds). These fluctuations may not be captured by default performance views, as they often show cumulative values. Refer to the chapter on analyzing performance fluctuations in the overall performance slow analysis for more information on how to diagnose and address short-term performance fluctuations."}, {"name": "concurrency_workload_high_cpu", "content": "If the CPU usage is high, it can cause overall performance slowdown"}, {"name": "concurrency_workload_high_io", "content": "If the IO usage is high, it can cause overall performance slowdown"}, {"name": "concurrency_workload_high_memory", "content": "If the memory usage is high, it can cause overall performance slowdown"}, {"name": "concurrency_workload_abnormal_events", "content": "If there are abnormal events, such as concurrent updates, it can cause overall performance slowdown"}, {"name": "concurrency_workload_performance_jitter", "content": "If there is performance jitter, it can cause overall performance slowdown"}, {"name": "concurrency_workload_high_cpu", "content": "High CPU usage in the database can be caused by poorly optimized SQL queries."}, {"name": "concurrency_workload_high_io", "content": "High IO can be caused by user statements that result in excessive physical reads. It can be identified by checking the 'n blocks fetched' and 'n blocks hit' fields in the dbe_pert_statement/dhe_pert_summary_statement views. If the difference between these two fields is high, it indicates a high number of physical reads. Additionally, the 'wait status' and 'wait event' fields in the pg_thread_wait_status view can be checked to see if there are any IO-related events or data file reads. The dhe_perf_local_active_session/gs_asp views can also be queried to check for records with Query events related to 'IO EVENT/DataFileRead' during a specific time period. Slow SQL queries with a high difference in 'n blocks fetched' and 'n blocks hit' fields or high data IO time can also indicate high IO. In the case of slow SQL, the 'details' field may contain information about the events causing the high IO."}, {"name": "concurrency_workload_high_memory_usage", "content": "High memory usage in the database can lead to performance issues. It is important to analyze and identify the specific areas of memory consumption."}, {"name": "concurrency_workload_slow_queries", "content": "Slow queries can cause overall performance degradation. It is important to identify the specific wait events and analyze their impact on performance."}, {"name": "concurrency_workload_performance_jitter", "content": "Performance jitter refers to fluctuations in performance over a period of time. It can be analyzed at different time scales."}, {"name": "concurrency_workload_performance_slow", "content": "The overall performance is slow, which does not meet the latency requirements of customer jobs or customer expectations."}, {"name": "concurrency_workload_performance_slow_wait_events", "content": "The overall performance is slow, and the wait events need to be analyzed to identify potential bottlenecks."}, {"name": "concurrency_workload_concurrent_query_optimization", "content": "GaussDB supports optimizing complex query execution using operator concurrency when system CU, memory, and IO resources are sufficient."}, {"name": "concurrency_workload_high_memory_usage", "content": "If the database process memory usage is consistently high, it can indicate memory overload."}, {"name": "concurrency_workload_high_concurrency_memory_usage", "content": "If the number of connections to the server is too high, it can lead to high memory usage."}, {"name": "concurrency_workload_high_memory_usage_sql", "content": "Some SQL statements may have high memory usage, leading to temporary memory spikes."}, {"name": "concurrency_workload_high_memory_usage", "content": "If the database process memory usage is consistently high, it can indicate memory overload."}, {"name": "concurrency_workload_memory_overload", "content": "If the memory usage of the database process is high, it can be caused by memory accumulation or other reasons"}, {"name": "concurrency_workload_memory_overload", "content": "In some cases, memory overload can cause cluster restarts, making it difficult to locate the cause of memory overload in real-time. In such cases, the following steps can be used to identify the cause of memory overload that has occurred in the past."}, {"name": "concurrency_workload_memory_usage_classification", "content": "Based on the memory usage information obtained from the query, the memory usage can be classified as follows: If dynamic used memory is large and dynamic used shared memory is small, it indicates that there is a high memory usage on threads and sessions. If dynamic used memory is large and dynamic used shared memory is similar, it indicates that there is a large dynamic memory usage on the global memory context. If only shared used memory is large, it indicates that there is a high usage of shared memory, which can be ignored. If other used memory is large, it is usually due to frequent memory allocation and deallocation during business execution, leading to excessive memory fragmentation."}, {"name": "concurrency_workload_slow_sql_execution", "content": "The SQL execution is slow and does not meet customer expectations and business requirements"}, {"name": "concurrency_workload_suboptimal_query_plan", "content": "The query plan for the slow SQL is suboptimal, leading to poor performance"}, {"name": "concurrency_workload_overall_performance_slow", "content": "The overall performance is slow and does not meet the customer's latency requirements or expectations. This can be caused by various reasons such as business-side issues, insufficient system resources, suboptimal usage of database kernel resources, concurrency issues, suboptimal database configuration, and non-optimal SQL."}, {"name": "concurrency_workload_high_cpu_usage", "content": "High CPU usage can cause performance issues in the database system."}, {"name": "concurrency_workload_high_IO", "content": "If the IO utilization is high or there are abnormal IO metrics such as high r await or high Vawalt, it may indicate IO issues. Possible causes include cache/raid configuration problems or disk throttling. To analyze the IO consumption of threads, you can use tools like pidstat or iotop. If the IO consumption is abnormal for TPLworker threads, it means that user SQL queries are consuming a lot of IO. You can use the lwtid from pg_thread_wait_status view to find the corresponding session information and optimize the queries to reduce IO consumption."}, {"name": "concurrency_workload_abnormal_persistent_events", "content": "Abnormal persistent events in the database can be categorized as STATS, UNUCX EVENT, LOXXEVENT, and IO BVENT. Identifying abnormal persistent events can be an effective way to diagnose overall performance slow query issues."}, {"name": "concurrency_workload_long_term_performance_degradation", "content": "Long-term performance degradation refers to a scenario where performance fluctuates significantly within a certain period of time (e.g., hours). To diagnose this issue, compare performance reports and investigate the following items: Top SQL, Top Wait Events, Load Profile, Cache/IO Stats, and Object Stats."}, {"name": "concurrency_workload_short_term_performance_fluctuation", "content": "Short-term performance fluctuation refers to a scenario where performance fluctuates at a finer granularity (e.g., seconds). This issue may not be captured by default performance views, but can be analyzed using the techniques described in the chapter on analyzing performance fluctuations in the overall performance slow query analysis section."}, {"name": "concurrency_workload_suboptimal_sql", "content": "Suboptimal SQL queries can negatively impact overall performance and potentially saturate the database's thread pool. Identifying suboptimal SQL queries is important for performance optimization."}, {"name": "concurrency_workload_high_cpu", "content": "If the CPU usage is high, it can cause overall performance degradation"}, {"name": "concurrency_workload_high_io", "content": "If the IO usage is high, it can cause overall performance degradation"}, {"name": "concurrency_workload_high_memory", "content": "If the memory usage is high, it can cause overall performance degradation"}, {"name": "concurrency_workload_abnormal_events", "content": "If there are abnormal events, such as concurrent updates, it can cause overall performance degradation"}, {"name": "concurrency_workload_performance_jitter", "content": "If there is performance jitter, it can cause overall performance degradation"}, {"name": "concurrency_workload_high_cpu", "content": "High CPU usage in the database can be caused by poorly optimized SQL queries."}, {"name": "concurrency_workload_high_cpu_user_statement", "content": "High CPU usage in the database can be caused by poorly optimized user SQL statements."}, {"name": "concurrency_workload_high_io", "content": "High IO can be caused by user statements that result in excessive physical reads. It can be identified by checking the 'n blocks fetched' and 'n blocks hit' fields in the dbe_pert_statement/dhe_pert_summary_statement views. If the difference between these two fields is high, it indicates a high number of physical reads. Additionally, the 'wait status' and 'wait event' fields in the pg_thread_wait_status view can be checked to see if there are any IO-related events or data file reads. The dhe_perf_local_active_session/gs_asp views can also be queried to check for records with Query events related to 'IO EVENT/DataFileRead' during a specific time period. Slow SQL queries with a high difference in 'n blocks fetched' and 'n blocks hit' fields or high data IO time can also indicate high IO. In the case of slow SQL, the 'details' field may contain information about the events causing the high IO."}, {"name": "concurrency_workload_performance_jitter", "content": "Performance jitter refers to fluctuations in performance over a period of time. It can be analyzed at different time scales."}, {"name": "concurrency_workload_concurrent_query_optimization", "content": "GaussDB supports optimizing complex query execution using operator concurrency when system CU, memory, and IO resources are sufficient."}, {"name": "concurrency_workload_high_memory_usage", "content": "If the database process memory usage is consistently high, it can indicate memory overload."}, {"name": "concurrency_workload_memory_overload", "content": "In some cases, memory overload can cause cluster environment restart, making it difficult to locate the cause of memory overload in real-time. In such cases, the following steps can be used to locate the cause of memory overload that has occurred in the past."}, {"name": "concurrency_workload_high_memory_usage", "content": "High memory usage can be caused by various reasons, including excessive memory fragmentation, delayed memory release, and other factors."}, {"name": "concurrency_workload_high_memory_usage", "content": "In the scenario of parallel decoding, if the reading log thread or decoding thread consumes too much memory, it can lead to insufficient memory and trigger memory error. The memory usage of ParallelDeeokeoispatcher or ParallelDecodelog is found to be relatively high."}, {"name": "concurrency_workload_high_memory_usage_parallel_decoding", "content": "In the scenario of parallel decoding, if the reading log thread or decoding thread consumes too much memory, it can lead to insufficient memory and trigger memory error. The memory usage of ParallelDeeokeoispatcher or ParallelDecodelog is found to be relatively high."}, {"name": "concurrency_workload_suboptimal_sql_plan", "content": "If the SQL plan chosen for the query is not optimal, it can cause slow SQL performance on partitioned tables"}, {"name": "concurrency_workload_high_cpu_usage", "content": "High CPU usage can be caused by the gaussdb process or certain SQL statements. It can be diagnosed by checking the CPU usage of the system and analyzing the WDR report."}, {"name": "concurrency_workload_high_IO", "content": "If the system shows high IO utilization, it can indicate potential performance issues. This can be observed through metrics such as %util in iostat, high r_await (usually greater than 3ms), or high w_await (usually greater than 3ms)."}, {"name": "concurrency_workload_high_memory_usage", "content": "If the memory usage of the database system is high, it can cause slow program execution."}, {"name": "concurrency_workload_suboptimal_database_usage", "content": "Suboptimal database usage can lead to performance degradation and inefficiency."}, {"name": "concurrency_workload_abnormal_wait_events", "content": "Abnormal wait events in the database can indicate performance issues"}, {"name": "concurrency_workload_long_term_performance_degradation", "content": "Long-term performance degradation refers to a scenario where the performance of the database fluctuates significantly over a certain period of time (hours). For example, the performance is normal from 8:00 to 9:00, but there is a significant performance fluctuation from 10:00 to 11:00. In this scenario, we can compare the WDR reports of the two time periods to identify any differences. The following aspects can be investigated: (1) Top SQL queries, (2) Top wait events, (3) Load profile, (4) Cache/IO statistics, (5) Object statistics."}, {"name": "concurrency_workload_short_term_performance_jitter", "content": "Short-term performance jitter refers to the situation where there are sudden fluctuations in performance at the second level. This is not adequately captured by the default one-hour interval of the WDR snapshot. It can be diagnosed by referring to the chapter on overall performance slow - analyzing performance jitter."}, {"name": "concurrency_workload_io_abnormality", "content": "This event indicates an IO abnormality. Possible causes include IO issues or inefficient IO usage due to business operations. Investigate and analyze further."}, {"name": "concurrency_workload_high_cpu_user_sql", "content": "If the high CPU usage is caused by the database process, it is usually due to poorly optimized SQL statements. This section focuses on CPU abnormalities caused by user statements."}, {"name": "concurrency_workload_high_io", "content": "High IO can be caused by user statements that result in excessive physical reads. It can be identified by checking the 'nblocks_fetched' and 'nblockshit' fields in the dbe_perf.statement/dbeperfsummary statement tables. If the difference between these two fields is high, it indicates a high number of physical reads."}, {"name": "concurrency_workload_high_memory_usage", "content": "If the database kernel has high memory usage, it can lead to various issues such as query errors and abnormal memory consumption on user sessions."}, {"name": "concurrency_workload_abnormal_wait_events", "content": "Abnormal wait events can cause overall slowness in the system. It is important to identify these wait events and analyze if they are causing performance issues. Common approaches to reduce abnormal wait events can be found in the 'Overall Performance Slow - Wait Event Analysis' chapter (Chapter 1.2)."}, {"name": "concurrency_workload_high_io", "content": "High IO can cause performance degradation. It is important to identify the tables or queries that are causing high IO and optimize them."}, {"name": "concurrency_workload_abnormal_wait_events", "content": "Abnormal wait events, including concurrent updates, can cause overall slowness in the system. It is important to identify these wait events and analyze if they are causing performance issues. Common approaches to reduce abnormal wait events can be found in the 'Overall Performance Slow - Wait Event Analysis' chapter (Chapter 1.2)."}, {"name": "concurrency_workload_concurrency_issues", "content": "Concurrency issues can cause performance degradation, such as increased response time, decreased TPS, or thread pool saturation."}, {"name": "concurrency_workload_concurrency_issues", "content": "Concurrency issues can cause performance degradation, such as increased response time, decreased TPS, or thread pool saturation."}, {"name": "concurrency_workload_concurrent_update_delete", "content": "If the business error is caused by concurrent UPDATE/DELETE operations on a partitioned table with row movement enabled, it can be resolved by disabling row movement or handling the business logic to avoid such conflicts."}, {"name": "concurrency_workload_concurrency_issues", "content": "Concurrency issues can cause increased latency, decreased TPS, or thread pool exhaustion. This is mainly caused by concurrent updates and resulting lock waits."}, {"name": "concurrency_workload_concurrent_updates", "content": "This event indicates concurrent updates. If there is a large number of these events, it may indicate a high level of concurrent updates causing overall business blocking. Use pg_thread_wait_status/dbe_perf.local_active_session/gs_asp to find the specific session_id causing the blockage."}, {"name": "io_disk_io_resource_contention", "content": "This piece of code checks for IO resource contention in the system. It does so by iterating through the IO utils of each device and checking if the maximum IO utils exceed the disk_ioutils_threshold. If there is contention, the function provides details on the device and the IO utils that exceed the threshold. It also suggests two possible causes of contention: competing processes outside the database and long transactions within the database. If there is contention, it is considered a root cause of the issue. If there is no contention, it is not a root cause."}, {"name": "io_disk_file_system_diagnostic_analysis", "content": "The code provided is diagnosing the usage and availability of file systems. \n\nThe variable `fs` stores the file systems retrieved using the `getfs()` function. \n`fs_info` is an empty string that will be used to store diagnostic information about the file systems. \n`flag_fs` is an integer variable initialized to 0 and will be used to count the number of file systems with issues. \n\nThe code then enters a loop where it iterates over each file system in `fs`. Within the loop, the code appends SQL queries to the `sql_fs` string. These queries collect information about the file system, such as its name (`fsmp`) and percentage of disk space used (`fspct`).\n\nThe code then proceeds to analyze each file system individually. If the file system's disk usage is between 80% and 95% and the amount of free space (`fsres`) is less than 500MB, a diagnostic message is added to `fs_info` indicating that the file system's usage is high and its free space is low. The `flag_fs` variable is incremented to indicate that an issue has been detected.\n\nSimilarly, if the file system's usage is between 80% and 95% and the free space is greater than 5GB, another diagnostic message is added to `fs_info` indicating that the file system's usage is high but its free space is sufficient. `flag_fs` is incremented again in this case.\n\nIf the file system's usage is equal to or greater than 95%, a diagnostic message is added to `fs_info` indicating that the file system's usage exceeds the critical threshold.\n\nFinally, if none of the above conditions are true, which means the file system's usage is below 80%, a diagnostic message is added to `fs_info` stating that the file system's usage is normal.\n\nIn summary, this code diagnoses the usage and availability of file systems and provides relevant diagnostic information based on pre-defined thresholds. The `sql_fs` and `fs_info` variables store information for further analysis and reporting. The `flag_fs` variable keeps track of the number of file systems with issues identified."}, {"name": "io_disk_disk_group_usage_diagnostic_analysis", "content": "The provided code appears to be a diagnostic script related to monitoring the usage of disk groups. The code iterates over a list called 'dg' and dynamically constructs a SQL query called 'sql_dg' by concatenating strings. The constructed query combines the names and percentages of disk groups ('dgname' and 'dgpct') using the \"union all\" clause.\n\nAfter constructing the SQL query, the code includes a series of conditional statements to analyze the disk group usage. If the percentage ('dgpct') is greater than 80 and less than 95, and the free space ('dgfree') is less than 2048, a diagnostic message is appended to the 'dg_info' string indicating that the disk group usage is high and the available space is low. The 'flag_dg' variable is incremented to indicate that a disk group exceeding the threshold has been identified.\n\nSimilarly, if the percentage is greater than 80 and less than 95, but the free space is greater than 10240, another diagnostic message is appended, indicating that the disk group usage is relatively high but the available space is sufficient. Again, 'flag_dg' is incremented.\n\nIf the percentage is equal to or greater than 95, a diagnostic message is appended to 'dg_info' indicating that the disk group usage is significantly exceeding the warning limit. 'flag_dg' is incremented accordingly.\n\nIf none of the above conditions are met, a message indicating normal disk group usage is appended to 'dg_info'.\n\nThe final line of the code trims off the trailing \"union all\" from the constructed SQL query.\n\nIn summary, this code analyzes the usage of disk groups and provides diagnostic messages based on defined thresholds and conditions. It iterates over a list of disk group information, constructs a SQL query, and appends diagnostic messages based on the calculated values."}, {"name": "io_disk_high_IO", "content": "If the IO utilization is high or there are abnormal IO metrics such as high r await or high Vawalt, it may indicate IO issues. Possible causes include cache/RAID configuration problems or disk throttling. To analyze the IO consumption of threads, you can use tools like pidstat or iotop. If the IO consumption is mainly caused by TPLworker threads, it means that user SQL queries are consuming a lot of IO. You can use the lwtid from pg_thread_wait_status to find the corresponding tid and sessionid, and then use the tid/sessionid to find the session information and specific queries from pg_stat_activity. To optimize the queries and reduce IO consumption, refer to the performance tuning chapter."}, {"name": "io_disk_abnormal_IO", "content": "If the IO utilization is high or there are abnormal IO metrics such as high r await or high Vawalt, it may indicate IO issues. Possible causes include cache/RAID configuration problems or disk throttling. To analyze the IO consumption of threads, you can use tools like pidstat or iotop. If the IO consumption is mainly caused by TPLworker threads, it means that user SQL queries are consuming a lot of IO. You can use the lwtid from pg_thread_wait_status to find the corresponding tid and sessionid, and then use the tid/sessionid to find the session information and specific queries from pg_stat_activity. To optimize the queries and reduce IO consumption, refer to the performance tuning chapter."}, {"name": "io_disk_abnormal_persistent_events", "content": "Abnormal persistent events in the database can impact overall performance. These events can be categorized as STATS, UNUCX EVENT, LOXXEVENT, and IO BVENT."}, {"name": "io_disk_high_io", "content": "If the IO usage is high, it can cause overall performance slowdown"}, {"name": "io_disk_high_io", "content": "High IO can be caused by user statements that result in excessive physical reads. It can be identified by checking the 'n blocks fetched' and 'n blocks hit' fields in the dbe_pert_statement/dhe_pert_summary_statement views. If the difference between these two fields is high, it indicates a high number of physical reads. Additionally, the 'wait status' and 'wait event' fields in the pg_thread_wait_status view can be checked to see if there are any IO-related events or data file reads. The dhe_perf_local_active_session/gs_asp views can also be queried to check for records with Query events related to 'IO EVENT/DataFileRead' during a specific time period. Slow SQL queries with a high difference in 'n blocks fetched' and 'n blocks hit' fields or high data IO time can also indicate high IO. In the case of slow SQL, the 'details' field may contain information about the events causing the high IO."}, {"name": "io_disk_high_IO", "content": "If the IO utilization is high or there are abnormal IO metrics such as high r await or high Vawalt, it may indicate IO issues. Possible causes include cache/raid configuration problems or disk throttling. To analyze the IO consumption of threads, you can use tools like pidstat or iotop. If the IO consumption is abnormal for TPLworker threads, it means that user SQL queries are consuming a lot of IO. You can use the lwtid from pg_thread_wait_status view to find the corresponding session information and optimize the queries to reduce IO consumption."}, {"name": "io_disk_abnormal_persistent_events", "content": "Abnormal persistent events in the database can be categorized as STATS, UNUCX EVENT, LOXXEVENT, and IO BVENT. Identifying abnormal persistent events can be an effective way to diagnose overall performance slow query issues."}, {"name": "io_disk_high_io", "content": "If the IO usage is high, it can cause overall performance degradation"}, {"name": "io_disk_high_io", "content": "High IO can be caused by user statements that result in excessive physical reads. It can be identified by checking the 'n blocks fetched' and 'n blocks hit' fields in the dbe_pert_statement/dhe_pert_summary_statement views. If the difference between these two fields is high, it indicates a high number of physical reads. Additionally, the 'wait status' and 'wait event' fields in the pg_thread_wait_status view can be checked to see if there are any IO-related events or data file reads. The dhe_perf_local_active_session/gs_asp views can also be queried to check for records with Query events related to 'IO EVENT/DataFileRead' during a specific time period. Slow SQL queries with a high difference in 'n blocks fetched' and 'n blocks hit' fields or high data IO time can also indicate high IO. In the case of slow SQL, the 'details' field may contain information about the events causing the high IO."}, {"name": "io_disk_high_IO", "content": "If the system shows high IO utilization, it can indicate potential performance issues. This can be observed through metrics such as %util in iostat, high r_await (usually greater than 3ms), or high w_await (usually greater than 3ms)."}, {"name": "io_disk_io_abnormality", "content": "This event indicates an IO abnormality. Possible causes include IO issues or inefficient IO usage due to business operations. Investigate and analyze further."}, {"name": "io_disk_high_io", "content": "High IO can be caused by user statements that result in excessive physical reads. It can be identified by checking the 'nblocks_fetched' and 'nblockshit' fields in the dbe_perf.statement/dbeperfsummary statement tables. If the difference between these two fields is high, it indicates a high number of physical reads."}, {"name": "io_disk_high_io", "content": "High IO can cause performance degradation. It is important to identify the tables or queries that are causing high IO and optimize them."}, {"name": "write_events_update_large_data", "content": "This function checks whether a table has a large number of tuples updated. If the number of updated tuples is greater than or equal to the specified threshold, it is considered a root cause. The function then provides details on the number of updated tuples and suggests making adjustments to the business. If the number of updated tuples is not above the threshold or if there is no plan parse information available, it is not a root cause."}, {"name": "write_events_insert_large_data", "content": "This function checks whether a query related table has a large number of inserted tuples. If the number of inserted tuples is greater than or equal to the specified threshold (stored in the variable \"inserted_tuples_threshold\"), it is considered a root cause. The function then calculates the ratio of inserted tuples to live tuples and provides a suggestion to make adjustments to the business. If the number of inserted tuples is less than the threshold, the function checks for insert operators and if any of them have a large number of rows inserted (greater than the threshold), it is considered a root cause and a suggestion is provided. If neither of these conditions are met, it is not a root cause."}, {"name": "write_events_delete_large_data", "content": "This function checks whether a table has too many tuples to be deleted. If the number of deleted tuples is greater than or equal to the specified threshold, it is considered a root cause and will be deleted in the future. If the number of deleted tuples is less than the threshold, the function checks whether there is a delete operation on a table with a large number of tuples. If so, it is also considered a root cause and the suggestion is to make adjustments to the business. If neither condition is met, it is not a root cause."}, {"name": "memory_accumulation", "content": "If temporary memory is not released in a timely manner during the execution of SQL statements, it can lead to memory accumulation."}, {"name": "memory_accumulation", "content": "If temporary memory is not released in a timely manner during the execution of SQL statements, it can lead to memory accumulation."}, {"name": "memory_accumulation", "content": "High memory usage in the database process can be caused by memory accumulation, such as temporary memory not being released in a timely manner or frequent memory allocation and deallocation"}, {"name": "memory_resource_contention", "content": "This function checks whether there is contention for memory resources by other processes outside the database. If the maximum system memory usage exceeds the detection threshold specified in the variable \"mem_usage_threshold\", the function sets the \"system_mem_contention\" key in the \"detail\" dictionary to indicate that the current system memory usage is significant. If the \"system_mem_contention\" key exists in the \"detail\" dictionary, the function suggests checking for external processes that may be consuming resources. If the function returns True, it indicates that memory resource contention is a root cause of the problem. If the function returns False, it means that memory resource contention is not a root cause."}, {"name": "memory_Memory_usage_analysis_diagnosis", "content": "The code lines are analyzing and diagnosing the memory usage of a system. The code first retrieves the memory information using the \"getmem\" function. Then, it fetches the long-term memory information using the \"getltmem\" function with specific parameters. \n\nNext, the code initializes variables to store information about memory and swap usage. There are also flag variables that indicate whether there are any memory or swap issues.\n\nThe code then constructs a SQL query to retrieve specific memory information for each record obtained from the \"getmem\" function. Based on the retrieved information, the code analyzes the memory usage and assigns appropriate diagnostic messages to the \"mem_info\" variable. \n\nIf the physical memory usage exceeds 90% and the free memory is below 200M and above 100M, it indicates that the physical memory usage is high and the available memory is low, which may pose performance risks. Similarly, if the physical memory usage exceeds 90% and the free memory is below 100M, it suggests a high memory usage and a significant performance risk.\n\nIf the physical memory usage exceeds 20% of the recent average, it is recommended to perform further checks. \n\nThe code also checks the swap usage. If the swap usage is above 50% and below 80%, it indicates a high swap usage and suggests further investigation. If the swap usage exceeds 80%, it suggests a high swap usage and recommends immediate investigation.\n\nAfter analyzing each record, the code appends the diagnostic messages for memory and swap usage to the respective variables.\n\nFinally, the code removes the last \"union all\" from the constructed SQL query.\n\nIn conclusion, the code analyzes the memory and swap usage of a system and generates diagnostic messages based on the specific threshold values and recent average usage. These messages provide insights into any potential memory and swap issues that may affect the system's performance."}, {"name": "memory_full", "content": "If the memory is full, it can cause slow program execution. To diagnose this issue, we need to identify the process with abnormal memory usage. In this case, we only consider the abnormal memory usage of the database process. For other processes, they are not representative and will not be described in detail here. To analyze the high memory usage of the database process, please refer to the relevant chapter on overall performance analysis."}, {"name": "high_memory", "content": "If the memory usage is high, it can cause overall performance slowdown"}, {"name": "high_memory_usage", "content": "High memory usage in the database can lead to performance issues. It is important to analyze and identify the specific areas of memory consumption."}, {"name": "high_memory_usage", "content": "If the database process memory usage is consistently high, it can indicate memory overload."}, {"name": "high_concurrency_memory_usage", "content": "If the number of connections to the server is too high, it can lead to high memory usage."}, {"name": "high_memory_usage_sql", "content": "Some SQL statements may have high memory usage, leading to temporary memory spikes."}, {"name": "high_memory_usage", "content": "If the database process memory usage is consistently high, it can indicate memory overload."}, {"name": "memory_overload", "content": "If the memory usage of the database process is high, it can be caused by memory accumulation or other reasons"}, {"name": "memory_overload", "content": "In some cases, memory overload can cause cluster restarts, making it difficult to locate the cause of memory overload in real-time. In such cases, the following steps can be used to identify the cause of memory overload that has occurred in the past."}, {"name": "memory_usage_classification", "content": "Based on the memory usage information obtained from the query, the memory usage can be classified as follows: If dynamic used memory is large and dynamic used shared memory is small, it indicates that there is a high memory usage on threads and sessions. If dynamic used memory is large and dynamic used shared memory is similar, it indicates that there is a large dynamic memory usage on the global memory context. If only shared used memory is large, it indicates that there is a high usage of shared memory, which can be ignored. If other used memory is large, it is usually due to frequent memory allocation and deallocation during business execution, leading to excessive memory fragmentation."}, {"name": "high_memory", "content": "If the memory usage is high, it can cause overall performance degradation"}, {"name": "high_memory_usage", "content": "If the database process memory usage is consistently high, it can indicate memory overload."}, {"name": "memory_overload", "content": "In some cases, memory overload can cause cluster environment restart, making it difficult to locate the cause of memory overload in real-time. In such cases, the following steps can be used to locate the cause of memory overload that has occurred in the past."}, {"name": "high_memory_usage", "content": "High memory usage can be caused by various reasons, including excessive memory fragmentation, delayed memory release, and other factors."}, {"name": "high_memory_usage", "content": "In the scenario of parallel decoding, if the reading log thread or decoding thread consumes too much memory, it can lead to insufficient memory and trigger memory error. The memory usage of ParallelDeeokeoispatcher or ParallelDecodelog is found to be relatively high."}, {"name": "high_memory_usage_parallel_decoding", "content": "In the scenario of parallel decoding, if the reading log thread or decoding thread consumes too much memory, it can lead to insufficient memory and trigger memory error. The memory usage of ParallelDeeokeoispatcher or ParallelDecodelog is found to be relatively high."}, {"name": "high_memory_usage", "content": "If the memory usage of the database system is high, it can cause slow program execution."}, {"name": "high_memory_usage", "content": "If the database kernel has high memory usage, it can lead to various issues such as query errors and abnormal memory consumption on user sessions."}, {"name": "recovery_abnormal_network_status", "content": "This piece of code checks for abnormal network status by analyzing packet loss rate and bandwidth usage. It first checks the receive and transmit drop rates for each device and appends any abnormal rates to a list of details. It then checks the bandwidth usage for each device and appends any abnormal rates to the same list of details. If any abnormal rates are found, the function sets the detail and suggestion attributes accordingly and returns True, indicating that abnormal network status is a root cause. If no abnormal rates are found, the function returns False, indicating that abnormal network status is not a root cause. The thresholds for abnormal packet loss rate and network bandwidth usage are obtained from the monitoring module."}, {"name": "recovery_network_unreachable", "content": "One common cause of network issues is when the database server is unable to establish a connection with the application server."}, {"name": "recovery_network_unreachable", "content": "One common cause of network issues is when the database server is unable to establish a connection with the application server"}, {"name": "abnormal_disaster_recovery_setup_process", "content": "The disaster recovery setup process is abnormal, which may cause issues in cross-region disaster recovery"}, {"name": "recovery_abnormal_failover_process", "content": "The failover process from standby to primary in a disaster recovery setup is abnormal"}, {"name": "recovery_abnormal_wltchover_process", "content": "The planned wltchover process is abnormal"}, {"name": "abnormal_disaster_recovery_performance_metrics", "content": "The performance metrics of the disaster recovery setup are abnormal"}, {"name": "disaster_recovery_process_abnormal", "content": "The disaster recovery setup process returns failure or times out"}, {"name": "recovery_failover_abnormal", "content": "The failover process of the disaster recovery to the primary cluster is abnormal, with some nodes not participating in the failover"}, {"name": "abnormal_disaster_recovery_status", "content": "The cluster-level PO value keeps increasing during the low business period, indicating abnormal disaster recovery. The ON status of the disaster recovery cluster shows 'Need repair (Disconnected)'. The QLACBT node in the disaster recovery cluster is faulty, and the instance status on this node shows 'Deleted' for CX, 'Unknown' for DN and CTU, and 'Main Standby Need repair (Connecting)' for some primary standby instances."}, {"name": "cpu_resource_contention", "content": "This function checks whether there is contention for CPU resources by other processes outside the database. If the maximum CPU usage of these processes exceeds the threshold specified in the variable \"cpu_usage_threshold\", the function sets the \"system_cpu_contention\" key in the \"detail\" dictionary to indicate the current user CPU usage. If this key is set, the function suggests handling exception processes in the system as a solution. If the \"system_cpu_contention\" key is not set, this issue is not a root cause."}, {"name": "cpu_os_resource_contention", "content": "This function checks for a potential issue where other processes outside the database may be occupying too many handle resources. If the system file descriptor (fds) occupation rate exceeds the detection threshold, it is considered a root cause and the function returns a boolean value of True. The system fds occupation rate is recorded in the diagnosis report along with a suggestion to determine whether the handle resource is occupied by the database or other processes. If the system fds occupation rate is below the tuple_number_threshold, it is not a root cause and the function returns a boolean value of False."}, {"name": "cpu_CPU_analysis_and_diagnostics", "content": "The code provided is analyzing the CPU workload and providing diagnostics based on certain conditions. \n\nFirst, the code retrieves CPU information using the \"getcpu\" function. It initializes variables \"sql_cpu\", \"flag_cpu\", and \"cpuinfo\". \n\nThen, it enters a loop to process each CPU resource. It concatenates SQL queries using the values from each resource, which will be used for further analysis. \n\nThe code then checks the value of the \"r\" attribute in each resource. If it is less than or equal to the variable \"cpun\" (representing the number of CPU threads), it indicates that the CPU load is not high. However, if it is greater than \"cpun\" but less than or equal to \"cpun\" multiplied by 2, it suggests that the CPU load is relatively high. If the value of \"r\" exceeds \"cpun\" multiplied by 2, it indicates a high CPU load with potential risks. The variable \"flag_cpu\" is incremented accordingly to keep track of the CPU load status.\n\nThe code then examines the value of the \"us\" attribute (representing CPU usage). If it is less than 20, it suggests that the CPU usage is not high. If it is between 20 and 80 (inclusive), it indicates normal CPU usage. If it is between 80 and 95 (inclusive), it suggests relatively high CPU usage. If the value exceeds 95 and the \"r\" value is greater than \"cpun\" multiplied by 2, it indicates a high CPU usage with a potential bottleneck. Otherwise, it concludes that the CPU is currently not experiencing performance bottlenecks.\n\nNext, the code evaluates the value of the \"sys\" attribute (representing system CPU usage). If it is less than 15, it suggests normal system CPU usage. If it is between 15 and 30 (inclusive), it indicates relatively high usage and requires attention to potential system issues. If it exceeds 30, it suggests significantly high system CPU usage, indicating the presence of serious vulnerabilities.\n\nBy analyzing the CPU information and applying various conditions, the code provides diagnostic information in the variable \"cpuinfo\". The variable \"flag_cpu\" keeps track of the number of identified CPU load issues."}, {"name": "high_cpu_usage", "content": "High CPU usage can cause slow SL execution and impact overall system performance"}, {"name": "high_cpu_usage_flame_graph", "content": "Flame graph analysis can be used to identify functions with high CPU usage and potential performance issues"}, {"name": "high_cpu_usage", "content": "High CPU usage can cause performance issues in the database system"}, {"name": "high_cpu", "content": "If the CPU usage is high, it can cause overall performance slowdown"}, {"name": "high_cpu", "content": "High CPU usage in the database can be caused by poorly optimized SQL queries."}, {"name": "high_cpu_usage", "content": "High CPU usage can cause performance issues in the database system."}, {"name": "high_cpu", "content": "If the CPU usage is high, it can cause overall performance degradation"}, {"name": "high_cpu", "content": "High CPU usage in the database can be caused by poorly optimized SQL queries."}, {"name": "high_cpu_user_statement", "content": "High CPU usage in the database can be caused by poorly optimized user SQL statements."}, {"name": "high_cpu_usage", "content": "High CPU usage can be caused by the gaussdb process or certain SQL statements. It can be diagnosed by checking the CPU usage of the system and analyzing the WDR report."}, {"name": "high_cpu_user_sql", "content": "If the high CPU usage is caused by the database process, it is usually due to poorly optimized SQL statements. This section focuses on CPU abnormalities caused by user statements."}, {"name": "query_operator_operator_penalty_parameters", "content": "The operator penalty parameters control the cost of certain operators in the query plan. By disabling these parameters, the optimizer will try to avoid selecting these operators in the execution plan."}, {"name": "query_operator_operator_cost_parameters", "content": "The operator cost parameters control the relative size of the operator cost calculation, which can accurately control the operator selection potential."}, {"name": "query_operator_operator_penalty_parameters", "content": "The operator penalty parameters control the cost of certain operators in the query plan. By disabling these parameters, the optimizer will try to avoid selecting these operators in the execution plan."}, {"name": "query_operator_operator_cost_parameters", "content": "The operator cost parameters control the relative size of the operator cost calculation, which can accurately control the operator selection potential."}, {"name": "query_operator_poor_join_performance", "content": "This code diagnoses poor performance in join operations. There are four main situations that can cause poor join performance: 1) when the GUC parameter 'enable_hashjoin' is set to 'off', which can result in the optimizer choosing NestLoop or other join operators even when HashJoin would be more suitable; 2) when the optimizer incorrectly chooses the NestLoop operator, even when 'set_hashjoin' is on; 3) when the join operation involves a large amount of data, which can lead to high execution costs; and 4) when the cost of the join operator is expensive. \n\nIn general, NestLoop is suitable when the inner table has a suitable index or when the tuple of the outer table is small (less than 10000), while HashJoin is suitable for tables with large amounts of data (more than 10000), although index will reduce HashJoin performance to a certain extent. Note that HashJoin requires high memory consumption.\n\nThe code checks for abnormal NestLoop, HashJoin, and MergeJoin operators, and identifies inappropriate join nodes based on the number of rows and cost rate. It also provides suggestions for optimization, such as setting 'enable_hashjoin' to 'on', optimizing SQL structure to reduce JOIN cost, and using temporary tables to filter data. \n\nIf the code finds any poor join performance, it is considered a root cause of the problem. Otherwise, it is not a root cause."}, {"name": "query_operator_complex_execution_plan", "content": "This is a function that checks for complex execution plans in SQL statements. The function identifies two cases that may cause complex execution plans: (1) a large number of join or group operations, and (2) a very complex execution plan based on its height. If the function identifies either of these cases, it sets the corresponding details and suggestions for the user. If the number of join operators exceeds the \"complex_operator_threshold\" or the plan height exceeds the \"plan_height_threshold\", the function considers it a root cause of the problem. Otherwise, it is not a root cause."}, {"name": "query_operator_poor_aggregation_performance", "content": "This function diagnoses poor aggregation performance in SQL queries. It identifies four potential root causes: (1) when the GUC parameter 'enable_hashagg' is set to 'off', resulting in a higher tendency to use the GroupAgg operator; (2) when the query includes scenarios like 'count(distinct col)', which makes HashAgg unavailable; (3) when the cost of the GroupAgg operator is expensive; and (4) when the cost of the HashAgg operator is expensive. The code checks for these conditions and provides detailed information and suggestions for each potential root cause. If none of these conditions are met, poor aggregation performance is not a root cause."}, {"name": "query_operator_abnormal_sql_structure", "content": "This function checks for a specific issue in the SQL structure that can lead to poor performance. If the rewritten SQL information is present, it indicates that the SQL structure is abnormal and can be a root cause of performance issues. The function provides a detailed description of the issue and suggests a solution to address it. If the rewritten SQL information is not present, it is not a root cause of the performance issue."}, {"name": "query_operator_poor_index_filtering", "content": "The query may have poor index filtering, leading to slow performance."}, {"name": "query_operator_slow_sql_execution", "content": "The SQL execution is slow and does not meet customer expectations and business requirements"}, {"name": "query_operator_poor_query_plan", "content": "The query plan is not optimal, leading to slow SQL execution"}, {"name": "query_operator_suboptimal_query_plan", "content": "The query plan is not optimal, leading to slow SQL execution"}, {"name": "query_operator_suboptimal_sql", "content": "Suboptimal SQL queries can negatively impact overall performance, potentially leading to thread pool saturation and other severe performance issues."}, {"name": "query_operator_slow_sql_execution", "content": "The SQL execution is slow and does not meet customer expectations and business requirements"}, {"name": "query_operator_suboptimal_query_plan", "content": "The query plan for the slow SQL is suboptimal, leading to poor performance"}, {"name": "database_configuration", "content": "Database configuration can affect performance. Common configuration issues include shared buffers being too small, insufficient work mem for sorting operations, and thread pool worker parameters being set too small."}, {"name": "database_configuration", "content": "Database configuration can affect performance. Common configuration issues include: shared buffers set too small, insufficient work_mem for sorting operators, and thread pool worker parameters set too small."}, {"name": "database_configuration", "content": "The database configuration may not be optimal, leading to performance issues. Common configuration issues include shared_buffers being too small, work_mem being too small for sorting operations, and thread_pool_attr being set too small."}, {"name": "configuration_work_mem", "content": "The work_mem parameter determines the amount of memory used for internal sorting operations and hash tables before writing to temporary disk files. It is used in operations such as ORDER BY, DISTINCT, and merge joins."}, {"name": "configuration_maintenance_work_mem", "content": "The maintenance_work_mem parameter determines the maximum amount of memory that can be used for maintenance operations such as VACUUM and CREATE INDEX. It affects the efficiency of these maintenance operations."}, {"name": "configuration_work_mem", "content": "The work_mem parameter determines the amount of memory used for internal sorting operations and hash tables before writing to temporary disk files. It is used in operations such as ORDER BY, DISTINCT, and merge joins."}, {"name": "configuration_maintenance_work_mem", "content": "The maintenance_work_mem parameter determines the maximum amount of memory that can be used for maintenance operations such as VACUUM and CREATE INDEX. It affects the efficiency of these maintenance operations."}, {"name": "configuration_quick_recovery", "content": "There is no fixed method for quick recovery as it depends on the specific problem. In some cases, coordination with the business side may be required for resolution."}, {"name": "configuration_quick_recovery", "content": "There is no fixed method for quick recovery as it depends on the specific problem. Sometimes it may require coordination with the business side to resolve the issue."}, {"name": "configuration_quick_recovery", "content": "There is no fixed method for quick recovery as it depends on the specific problem. Sometimes, coordination with the business side may be required for resolution."}]